{"config": {"indexing": "full", "lang": ["en"], "min_search_length": 3, "prebuild_index": false, "separator": "[\\s\\-]+"}, "docs": [{"location": "", "text": "", "title": "Home"}, {"location": "architecture/", "text": "Architecture Blockcore is an eco-system of many parts and this section describes the whole eco-system from a top-down perspective. The underlaying foundation is our blockchain node software, which can be used to run an UTXO-based blockchain that is similar to Bitcoin, but with added support to run Proof-of-Stake. Our software also supports Proof-of-Work blockchains. Each node has the full data of the blockchain, which normally does not contain a lot of additional data other than limited OP_RETURN data. Nodes should not be exposed to public consumption. The indexer is responsible for building an queryable database of the history of the blockchain, for specific addresses, transactions and blocks. Ontop of the indexer, we have built different user interface surfaces such as the explorer, which allows insight into the blockchain, including rich lists, network nodes, known public addresses, and more. Our extension is an non-custodial wallet that runs in the web browser and is distributed on add-ons stores for easy discovery, installation and automatic updates. The extension relies on the indexer to access blockchain data. Blockcore Hub is a full-node wallet, which is the software you can give to your advanced users that will be performing Proof-of-Stake operations. Blockcore Hub is a full-node, meaning that it downloads the entire blockchain. This is the optimal wallet to use for improve privacy. Blockcore Tipbot is our tipping-bot software that allows users to easily give and receive tips in the form of coins and tokens. The tipbot is a custodial service, meaning that the keys does not belong to the individual users, so only use it for smaller amounts. Users can withdraw from their tipbot balance into Blockcore Hub or Blockcore Extension wallets. Blockcore Vault is our server software that allows distribute data storage and sharing. It implements open standards for decentralized identity (DID). The Blockcore Vault software can store a users verifiable credentials, which can be anything from private direct messages, to NFTs, receipts from purchases, favorite music, videos and everything else. It supports both public (unencrypted) information and encrypted (private) information to be hosted. We have cross-system documentation for all of our software, in combination with tooling for generating new blockchains and more. We also run a community provided and supported server infrastructure of blockchain nodes, tipbots, indexers, explorers and more.", "title": "Architecture"}, {"location": "architecture/#architecture", "text": "Blockcore is an eco-system of many parts and this section describes the whole eco-system from a top-down perspective. The underlaying foundation is our blockchain node software, which can be used to run an UTXO-based blockchain that is similar to Bitcoin, but with added support to run Proof-of-Stake. Our software also supports Proof-of-Work blockchains. Each node has the full data of the blockchain, which normally does not contain a lot of additional data other than limited OP_RETURN data. Nodes should not be exposed to public consumption. The indexer is responsible for building an queryable database of the history of the blockchain, for specific addresses, transactions and blocks. Ontop of the indexer, we have built different user interface surfaces such as the explorer, which allows insight into the blockchain, including rich lists, network nodes, known public addresses, and more. Our extension is an non-custodial wallet that runs in the web browser and is distributed on add-ons stores for easy discovery, installation and automatic updates. The extension relies on the indexer to access blockchain data. Blockcore Hub is a full-node wallet, which is the software you can give to your advanced users that will be performing Proof-of-Stake operations. Blockcore Hub is a full-node, meaning that it downloads the entire blockchain. This is the optimal wallet to use for improve privacy. Blockcore Tipbot is our tipping-bot software that allows users to easily give and receive tips in the form of coins and tokens. The tipbot is a custodial service, meaning that the keys does not belong to the individual users, so only use it for smaller amounts. Users can withdraw from their tipbot balance into Blockcore Hub or Blockcore Extension wallets. Blockcore Vault is our server software that allows distribute data storage and sharing. It implements open standards for decentralized identity (DID). The Blockcore Vault software can store a users verifiable credentials, which can be anything from private direct messages, to NFTs, receipts from purchases, favorite music, videos and everything else. It supports both public (unencrypted) information and encrypted (private) information to be hosted. We have cross-system documentation for all of our software, in combination with tooling for generating new blockchains and more. We also run a community provided and supported server infrastructure of blockchain nodes, tipbots, indexers, explorers and more.", "title": "Architecture"}, {"location": "community/", "text": "Community This project is nothing without its community! Join us:", "title": "Community"}, {"location": "community/#community", "text": "This project is nothing without its community! Join us:", "title": "Community"}, {"location": "contribute/", "text": "How to contribute to Blockcore? Blockcore is built and maintained entirely by volunteer contributors around the internet. We welcome and appreciate new contributions, whether you're a developer, a five language speaking individual or an average Joe or Jane that want's to help in any way possible. Developers If you're a developer looking to help, but you're not sure where to begin, check the good first issue label , which contains small pieces of work that have been specifically flagged as being friendly to new contributors. Contributors looking to do something a bit more challenging, before opening a pull request, please create an issue or join our community chat to get early feedback, discuss best ways to tackle the problem and to ensure there is no work duplication. We are actively looking for developers who can take on and resolve GitHub issues and help with development. If you would like to help us, but need some guidance, the Discord is the place to ask questions. See the Development section. Community You can help Blockcore even if you're not a developer. The easiest way is to use the software as a business or individual, provide feedback and report any bugs or issues you or your customers encounter. Another great way is to join the community and help others troubleshoot by sharing information you may have from your experience using Blockcore. Consider helping newcomers like the community helped you. Documentation & Blog Helping us keeping the present Documentation up-to-date is an important contribution because Blockcore evolves at each release. Writing articles helps spread the word on new features being implemented, or provides tutorials on how to use them. Both can be done by anyone, tech-savvy or not. Video & Graphics Making videos that promote some features or that show how Blockcore works is a great way to help. Hosting Providers The Blockcore community is looking for more VPS hosting providers to host public blockchain nodes, making them more decentralized and widely-available. Spreading the word You like Blockcore, what it stands for and what it offers ? Spread the word ! It's the easiest way to contribute and help the community.", "title": "Contribute"}, {"location": "contribute/#how-to-contribute-to-blockcore", "text": "Blockcore is built and maintained entirely by volunteer contributors around the internet. We welcome and appreciate new contributions, whether you're a developer, a five language speaking individual or an average Joe or Jane that want's to help in any way possible.", "title": "How to contribute to Blockcore?"}, {"location": "contribute/#developers", "text": "If you're a developer looking to help, but you're not sure where to begin, check the good first issue label , which contains small pieces of work that have been specifically flagged as being friendly to new contributors. Contributors looking to do something a bit more challenging, before opening a pull request, please create an issue or join our community chat to get early feedback, discuss best ways to tackle the problem and to ensure there is no work duplication. We are actively looking for developers who can take on and resolve GitHub issues and help with development. If you would like to help us, but need some guidance, the Discord is the place to ask questions. See the Development section.", "title": "Developers"}, {"location": "contribute/#community", "text": "You can help Blockcore even if you're not a developer. The easiest way is to use the software as a business or individual, provide feedback and report any bugs or issues you or your customers encounter. Another great way is to join the community and help others troubleshoot by sharing information you may have from your experience using Blockcore. Consider helping newcomers like the community helped you.", "title": "Community"}, {"location": "contribute/#documentation-blog", "text": "Helping us keeping the present Documentation up-to-date is an important contribution because Blockcore evolves at each release. Writing articles helps spread the word on new features being implemented, or provides tutorials on how to use them. Both can be done by anyone, tech-savvy or not.", "title": "Documentation &amp; Blog"}, {"location": "contribute/#video-graphics", "text": "Making videos that promote some features or that show how Blockcore works is a great way to help.", "title": "Video &amp; Graphics"}, {"location": "contribute/#hosting-providers", "text": "The Blockcore community is looking for more VPS hosting providers to host public blockchain nodes, making them more decentralized and widely-available.", "title": "Hosting Providers"}, {"location": "contribute/#spreading-the-word", "text": "You like Blockcore, what it stands for and what it offers ? Spread the word ! It's the easiest way to contribute and help the community.", "title": "Spreading the word"}, {"location": "development/", "text": "Contributing to Blockcore Try to follow the .NET Core guidlines. Commit Messages Please format commit messages as follows (based on this excellent post ): 1 2 3 4 5 6 7 8 9 10 Summarize change in 50 characters or less Provide more detail after the first line. Leave one blank line below the summary and wrap all lines at 72 characters or less. If the change fixes an issue, leave another blank line after the final paragraph and indicate which issue is fixed in the specific format below. Fix #42 DOs and DON'Ts DO follow our coding style DO follow our code commenting policy and guidelines DO give priority to the current style of the project or file you're changing even if it diverges from the general guidelines. DO include tests when adding new features. When fixing bugs, start with adding a test that highlights how the current behavior is broken. DO keep the discussions focused. When a new or related topic comes up it's often better to create new issue than to side track the discussion. DO blog and tweet (or whatever) about your contributions, frequently! DON'T surprise us with big pull requests. Instead, file an issue and start a discussion so we can agree on a direction before you invest a large amount of time. DON'T commit code that you didn't write. If you find code that you think is a good fit to add to .NET Core, file an issue and start a discussion before proceeding. DON'T submit PRs that alter licensing related files or headers. If you believe there's a problem with them, file an issue and we'll be happy to discuss it. Contributing By contributing to this repository, you agree to license your work under the BlockCore license unless specified otherwise at the top of the file itself. Any work contributed where you are not the original author must contain its license header with the original author(s) and source.", "title": "Development"}, {"location": "development/#contributing-to-blockcore", "text": "Try to follow the .NET Core guidlines.", "title": "Contributing to Blockcore"}, {"location": "development/#commit-messages", "text": "Please format commit messages as follows (based on this excellent post ): 1 2 3 4 5 6 7 8 9 10 Summarize change in 50 characters or less Provide more detail after the first line. Leave one blank line below the summary and wrap all lines at 72 characters or less. If the change fixes an issue, leave another blank line after the final paragraph and indicate which issue is fixed in the specific format below. Fix #42", "title": "Commit Messages"}, {"location": "development/#dos-and-donts", "text": "DO follow our coding style DO follow our code commenting policy and guidelines DO give priority to the current style of the project or file you're changing even if it diverges from the general guidelines. DO include tests when adding new features. When fixing bugs, start with adding a test that highlights how the current behavior is broken. DO keep the discussions focused. When a new or related topic comes up it's often better to create new issue than to side track the discussion. DO blog and tweet (or whatever) about your contributions, frequently! DON'T surprise us with big pull requests. Instead, file an issue and start a discussion so we can agree on a direction before you invest a large amount of time. DON'T commit code that you didn't write. If you find code that you think is a good fit to add to .NET Core, file an issue and start a discussion before proceeding. DON'T submit PRs that alter licensing related files or headers. If you believe there's a problem with them, file an issue and we'll be happy to discuss it.", "title": "DOs and DON'Ts"}, {"location": "development/#contributing", "text": "By contributing to this repository, you agree to license your work under the BlockCore license unless specified otherwise at the top of the file itself. Any work contributed where you are not the original author must contain its license header with the original author(s) and source.", "title": "Contributing"}, {"location": "introduction/", "text": "Blockcore is a platform that enables you to build your own blockchains. Blockcore is the foundation for realizing blockchains and includes core functionality to create your own custom blockchain with a lot of tooling supporting your blockchain. The tooling as part of the Blockcore platform includes; Block Explorer, Block Indexing, Block Analytics, Wallets, API Wallet Service, Developer Tooling, Documentation and more. Blockcore is under continuous development to stay at the cutting edge of Bitcoin and blockchain technology. We invite you to engage with our community. Features Blockcore is a platform to build Layer 1 consensus networks based on the Bitcoin protocol Compatible with Bitcoin, and other chains built on Blockcore. Built on the .NET Core framework and written entirely in C#. SegWit supported APIs and SDKs for app developers Ecosystems of software, including block explorer, indexers, wallet software and more. Create your own blockchain One of our goals is to make it super easy for you to start developing your own blockchain. Watch this video on how you can quickly get started: Who is responsible Blockcore is code, not a company. It's a gathering of individuals who contribute voluntarily to open source software development. Contributing Pull requests are welcome and appreciated. If you'd like to support the project, please visit the sponsors page . Call to Action! Join to give feedback, ask for features, support, etc. Discord server: https://www.blockcore.net/discord CI Current status", "title": "Introduction"}, {"location": "introduction/#blockcore-is-a-platform-that-enables-you-to-build-your-own-blockchains", "text": "Blockcore is the foundation for realizing blockchains and includes core functionality to create your own custom blockchain with a lot of tooling supporting your blockchain. The tooling as part of the Blockcore platform includes; Block Explorer, Block Indexing, Block Analytics, Wallets, API Wallet Service, Developer Tooling, Documentation and more. Blockcore is under continuous development to stay at the cutting edge of Bitcoin and blockchain technology. We invite you to engage with our community.", "title": "Blockcore is a platform that enables you to build your own blockchains."}, {"location": "introduction/#features", "text": "Blockcore is a platform to build Layer 1 consensus networks based on the Bitcoin protocol Compatible with Bitcoin, and other chains built on Blockcore. Built on the .NET Core framework and written entirely in C#. SegWit supported APIs and SDKs for app developers Ecosystems of software, including block explorer, indexers, wallet software and more.", "title": "Features"}, {"location": "introduction/#create-your-own-blockchain", "text": "One of our goals is to make it super easy for you to start developing your own blockchain. Watch this video on how you can quickly get started:", "title": "Create your own blockchain"}, {"location": "introduction/#who-is-responsible", "text": "Blockcore is code, not a company. It's a gathering of individuals who contribute voluntarily to open source software development.", "title": "Who is responsible"}, {"location": "introduction/#contributing", "text": "Pull requests are welcome and appreciated. If you'd like to support the project, please visit the sponsors page .", "title": "Contributing"}, {"location": "introduction/#call-to-action", "text": "Join to give feedback, ask for features, support, etc. Discord server: https://www.blockcore.net/discord", "title": "Call to Action!"}, {"location": "introduction/#ci", "text": "Current status", "title": "CI"}, {"location": "links/", "text": "Links Website GitHub Issue Track", "title": "Links"}, {"location": "links/#links", "text": "Website GitHub Issue Track", "title": "Links"}, {"location": "overview/", "text": "Overview Node The node software is a full node software that runs the blockchain network. It is compatible with Bitcoin and utilized by other blockchains at the primary full node. To build your own blockchain based on Blockcore you have two options; perform a fork of our primary source code, this is preferred if you need to radically modify the blockchain functionality. The other way is to utilize our blockchain template, which is generated and relies on published on NuGet. This enables you to quickly and easily launch your own blockchain, and you will easily be able to get latest updates without messing with source code. To simplify using our tools, we have made instructions and generators available here. Source repo for template-based node: https://github.com/block-core/blockcore-node (Preferred) Source repo for fork-based node: https://github.com/block-core/blockcore Extension The Blockcore Extension is an Non-Custodial HD wallet in your browser for Coins, Tokens, Identities, NFTs and more. Extension keeps your identities and keys safe, while allowing you to communicate securely and authenticate with web apps (Web3 provider). https://github.com/block-core/blockcore-extension Learn more Explorer Together with the Blockcore Indexer (below), we have made the Blockcore Explorer. If you have a normal Blockcore based blockchain, it is super easy to add support for your custom chain and deploy your blockchain explorer. The explorer has sections for Network and Insight, which shows statistics on the network and supply (total supply, circulating supply, rewards) and economy information on the blockchain. https://github.com/block-core/blockcore-explorer Indexer Being able to look up blocks, transactions and addresses is an important part of any blockchain. It is very easy to add your own custom blockchain to the explorer. https://github.com/block-core/blockcore-indexer Tipbot Blockcore Tipbot is a generic tipping bot for Discord (future support for Twitch and Twitter is being added) that supports all Blockcore blockchains. It is easy to configure and use, and allows communities to easily tip based on community work and contributions. https://github.com/block-core/blockcore-tipbot Decentralized Identifiers Blockcore is committed to supporting the ecosystem of Decentralized Identifiers (DIDs) and the DID method for Blockcore is \" did:is: \". This is a work in progress. Specification: https://github.com/block-core/blockcore-did-method", "title": "Overview"}, {"location": "overview/#overview", "text": "", "title": "Overview"}, {"location": "overview/#node", "text": "The node software is a full node software that runs the blockchain network. It is compatible with Bitcoin and utilized by other blockchains at the primary full node. To build your own blockchain based on Blockcore you have two options; perform a fork of our primary source code, this is preferred if you need to radically modify the blockchain functionality. The other way is to utilize our blockchain template, which is generated and relies on published on NuGet. This enables you to quickly and easily launch your own blockchain, and you will easily be able to get latest updates without messing with source code. To simplify using our tools, we have made instructions and generators available here. Source repo for template-based node: https://github.com/block-core/blockcore-node (Preferred) Source repo for fork-based node: https://github.com/block-core/blockcore", "title": "Node"}, {"location": "overview/#extension", "text": "The Blockcore Extension is an Non-Custodial HD wallet in your browser for Coins, Tokens, Identities, NFTs and more. Extension keeps your identities and keys safe, while allowing you to communicate securely and authenticate with web apps (Web3 provider). https://github.com/block-core/blockcore-extension Learn more", "title": "Extension"}, {"location": "overview/#explorer", "text": "Together with the Blockcore Indexer (below), we have made the Blockcore Explorer. If you have a normal Blockcore based blockchain, it is super easy to add support for your custom chain and deploy your blockchain explorer. The explorer has sections for Network and Insight, which shows statistics on the network and supply (total supply, circulating supply, rewards) and economy information on the blockchain. https://github.com/block-core/blockcore-explorer", "title": "Explorer"}, {"location": "overview/#indexer", "text": "Being able to look up blocks, transactions and addresses is an important part of any blockchain. It is very easy to add your own custom blockchain to the explorer. https://github.com/block-core/blockcore-indexer", "title": "Indexer"}, {"location": "overview/#tipbot", "text": "Blockcore Tipbot is a generic tipping bot for Discord (future support for Twitch and Twitter is being added) that supports all Blockcore blockchains. It is easy to configure and use, and allows communities to easily tip based on community work and contributions. https://github.com/block-core/blockcore-tipbot", "title": "Tipbot"}, {"location": "overview/#decentralized-identifiers", "text": "Blockcore is committed to supporting the ecosystem of Decentralized Identifiers (DIDs) and the DID method for Blockcore is \" did:is: \". This is a work in progress. Specification: https://github.com/block-core/blockcore-did-method", "title": "Decentralized Identifiers"}, {"location": "referencenodes/", "text": "While individual blockchains that build on the Blockcore Platform will have their own official node and wallet software, we also provide a set of reference nodes. This software is provided without any support, use at your own risk. Blockcore is available for the below listed blockchains. Bitcoin chains/BTC.json docker/BTC/docker-compose.yml City Chain chains/CITY.json docker/CITY/docker-compose.yml SERF chains/SERF.json docker/SERF/docker-compose.yml Impleum chains/IMPLX.json docker/IMPLX/docker-compose.yml OpenExO chains/EXOS.json docker/EXOS/docker-compose.yml Rutanio chains/RUTA.json docker/RUTA/docker-compose.yml Solaris chains/XLR.json docker/XLR/explorer.yml docker/XLR/indexer.yml Stratis chains/STRAX.json docker/STRAX/docker-compose.yml x42 chains/X42.json docker/X42/docker-compose.yml XDS chains/XDS.json docker/XDS/docker-compose.yml X1 chains/X1.json docker/X1/docker-compose.yml XRC chains/XRC.json docker/XRC/docker-compose.yml HOMECOIN chains/HOME.json docker/HOME/docker-compose.yml Download Go to the releases page to find the packaged nodes for various chains. Separate downloads for Windows, Linux and macOS is available. Docker All our Blockcore Reference Nodes is published to our Docker Hub . It is super easy to spin up a new instance of any of the nodes, they all follow the same syntax (name and version). We advice on using specific version when using docker, like our example below. Run the Blockcore Reference Node for XDS blockchain in interactive mode: 1 docker run blockcore/node-xds:1.0.4 To spin up a docker container instance in the background, apply the \"-d\" tag. Run the Blockcore Reference Node for City Chain blockchain in background: 1 docker run blockcore/node-city:1.0.4 Support and compatibility These are all unofficial node software. They are not supported in any way. The software can be incompatible with the blockchain they are built for. You run the risk of getting your IP address banned on the blockchain if you run node software that violated the blockchain consensus. Please refer to the official software for individual blockchains for supported node software.", "title": "Reference Nodes"}, {"location": "referencenodes/#bitcoin", "text": "chains/BTC.json docker/BTC/docker-compose.yml", "title": "Bitcoin"}, {"location": "referencenodes/#city-chain", "text": "chains/CITY.json docker/CITY/docker-compose.yml", "title": "City Chain"}, {"location": "referencenodes/#serf", "text": "chains/SERF.json docker/SERF/docker-compose.yml", "title": "SERF"}, {"location": "referencenodes/#impleum", "text": "chains/IMPLX.json docker/IMPLX/docker-compose.yml", "title": "Impleum"}, {"location": "referencenodes/#openexo", "text": "chains/EXOS.json docker/EXOS/docker-compose.yml", "title": "OpenExO"}, {"location": "referencenodes/#rutanio", "text": "chains/RUTA.json docker/RUTA/docker-compose.yml", "title": "Rutanio"}, {"location": "referencenodes/#solaris", "text": "chains/XLR.json docker/XLR/explorer.yml docker/XLR/indexer.yml", "title": "Solaris"}, {"location": "referencenodes/#stratis", "text": "chains/STRAX.json docker/STRAX/docker-compose.yml", "title": "Stratis"}, {"location": "referencenodes/#x42", "text": "chains/X42.json docker/X42/docker-compose.yml", "title": "x42"}, {"location": "referencenodes/#xds", "text": "chains/XDS.json docker/XDS/docker-compose.yml", "title": "XDS"}, {"location": "referencenodes/#x1", "text": "chains/X1.json docker/X1/docker-compose.yml", "title": "X1"}, {"location": "referencenodes/#xrc", "text": "chains/XRC.json docker/XRC/docker-compose.yml", "title": "XRC"}, {"location": "referencenodes/#homecoin", "text": "chains/HOME.json docker/HOME/docker-compose.yml", "title": "HOMECOIN"}, {"location": "referencenodes/#download", "text": "Go to the releases page to find the packaged nodes for various chains. Separate downloads for Windows, Linux and macOS is available.", "title": "Download"}, {"location": "referencenodes/#docker", "text": "All our Blockcore Reference Nodes is published to our Docker Hub . It is super easy to spin up a new instance of any of the nodes, they all follow the same syntax (name and version). We advice on using specific version when using docker, like our example below. Run the Blockcore Reference Node for XDS blockchain in interactive mode: 1 docker run blockcore/node-xds:1.0.4 To spin up a docker container instance in the background, apply the \"-d\" tag. Run the Blockcore Reference Node for City Chain blockchain in background: 1 docker run blockcore/node-city:1.0.4", "title": "Docker"}, {"location": "referencenodes/#support-and-compatibility", "text": "These are all unofficial node software. They are not supported in any way. The software can be incompatible with the blockchain they are built for. You run the risk of getting your IP address banned on the blockchain if you run node software that violated the blockchain consensus. Please refer to the official software for individual blockchains for supported node software.", "title": "Support and compatibility"}, {"location": "release-process/", "text": "Release Process Blockchain Release Process Instructions to release your own blockchain software will be added here. Official Blockcore Release Process This process describes the steps that is needed to go through to release new and updated packages and software. RocksDB Native and NuGet package 1: https://github.com/block-core/blockcore-rocksdb-native 2: https://github.com/block-core/blockcore-rocksdb If there is a new release of RocksDB, then RocksDB native must be built and released. Next step is to build the NuGet package, then release when ready. After releasing on NuGet, wait at least 10 minutes before proceeding to ensure scanning, approval and indexing of the package is completed. Blockcore NuGet packages 3: https://github.com/block-core/blockcore The main repository that contains the majority of our NuGet packages, must be updated to new version. After a build is completed from the master branch, then a new release will be added to the repository, in draft state. Verify the NuGet packages locally by downloading and installing, if possible. To publish new version of NuGet packages to the NuGet website, simply edit the new draft release and publish it. This will automatically trigger an workflow that will publish the NuGet packages. Wait at least 10 minutes before proceeding, as the NuGet packages must be scanned for malware, approved and indexed. Blockcore Features 4: https://github.com/block-core/blockcore-features We maintain some custom features that extends the basic functionality. Upgrade the version number, perform a build, and publish the draft release. The source code has reference to Blockcore NuGet packages in the pattern \"1.1.*\", which means each build will always take the latest available. There is no need to manually update NuGet packages from Visual Studio, except of course other third party packages that might need to be updated. Wait at least 10 minutes before proceeding, due to NuGet scanning, approval and indexing. Blockcore Reference Nodes 5: https://github.com/block-core/blockcore-nodes We maintain an multi-node that can be utilized to run all the Blockcore-based blockchains using a single package. Upgrade the version number, perform a build, and publish the draft release. The source code has reference to Blockcore NuGet packages in the pattern \"1.1.*\", which means each build will always take the latest available. There is no need to manually update NuGet packages from Visual Studio, except of course other third party packages that might need to be updated. When the draft release is published, the workflow will automatically build and publish container images to Docker Hub. Image: https://hub.docker.com/repository/docker/blockcore/node-multi Blockcore Indexer 6: https://github.com/block-core/blockcore-indexer Add any new network NuGet packages, if new blockchains has been added. When the draft release is published, the workflow will automatically build and publish container images to Docker Hub. Image: https://hub.docker.com/repository/docker/blockcore/indexer Blockcore Explorer 7: https://github.com/block-core/blockcore-explorer Update the version, also verify if there is any NPM packages that should be updated on the UI project. When the draft release is published, the workflow will automatically build and publish container images to Docker Hub. The Explorer does not depend on the network NuGet packages and does not need to be updated for every new blockchain. Image: https://hub.docker.com/repository/docker/blockcore/explorer Blockcore TipBot 8: https://github.com/block-core/blockcore-tipbot The TipBot is hosted by Blockcore as a community service, but we advice teams to use their own dedicated tipbot for individual blockchains. The TipBot does not depend on the network NuGet packages and does not need to be updated for every new blockchain. Blockcore Hub 9: https://github.com/block-core/blockcore-hub Blockcore Hub requires that the multi-node to be released first, it embeds the full node software. Upgrade packages and version, then publish the draft release after build is complete. Chains configurations 10: https://github.com/block-core/chaininfo The Blockcore software utilizes an hosted server for configuration. This makes it possible to update configurations of software without re-installations and updated releases. It is the responsibility of individual blockchains to maintain their own configurations, but the Blockcore team will support and help with instructions. The configurations are published on the website: https://chains.blockcore.net/", "title": "Release Process"}, {"location": "release-process/#release-process", "text": "", "title": "Release Process"}, {"location": "release-process/#blockchain-release-process", "text": "Instructions to release your own blockchain software will be added here.", "title": "Blockchain Release Process"}, {"location": "release-process/#official-blockcore-release-process", "text": "This process describes the steps that is needed to go through to release new and updated packages and software.", "title": "Official Blockcore Release Process"}, {"location": "release-process/#rocksdb-native-and-nuget-package", "text": "1: https://github.com/block-core/blockcore-rocksdb-native 2: https://github.com/block-core/blockcore-rocksdb If there is a new release of RocksDB, then RocksDB native must be built and released. Next step is to build the NuGet package, then release when ready. After releasing on NuGet, wait at least 10 minutes before proceeding to ensure scanning, approval and indexing of the package is completed.", "title": "RocksDB Native and NuGet package"}, {"location": "release-process/#blockcore-nuget-packages", "text": "3: https://github.com/block-core/blockcore The main repository that contains the majority of our NuGet packages, must be updated to new version. After a build is completed from the master branch, then a new release will be added to the repository, in draft state. Verify the NuGet packages locally by downloading and installing, if possible. To publish new version of NuGet packages to the NuGet website, simply edit the new draft release and publish it. This will automatically trigger an workflow that will publish the NuGet packages. Wait at least 10 minutes before proceeding, as the NuGet packages must be scanned for malware, approved and indexed.", "title": "Blockcore NuGet packages"}, {"location": "release-process/#blockcore-features", "text": "4: https://github.com/block-core/blockcore-features We maintain some custom features that extends the basic functionality. Upgrade the version number, perform a build, and publish the draft release. The source code has reference to Blockcore NuGet packages in the pattern \"1.1.*\", which means each build will always take the latest available. There is no need to manually update NuGet packages from Visual Studio, except of course other third party packages that might need to be updated. Wait at least 10 minutes before proceeding, due to NuGet scanning, approval and indexing.", "title": "Blockcore Features"}, {"location": "release-process/#blockcore-reference-nodes", "text": "5: https://github.com/block-core/blockcore-nodes We maintain an multi-node that can be utilized to run all the Blockcore-based blockchains using a single package. Upgrade the version number, perform a build, and publish the draft release. The source code has reference to Blockcore NuGet packages in the pattern \"1.1.*\", which means each build will always take the latest available. There is no need to manually update NuGet packages from Visual Studio, except of course other third party packages that might need to be updated. When the draft release is published, the workflow will automatically build and publish container images to Docker Hub. Image: https://hub.docker.com/repository/docker/blockcore/node-multi", "title": "Blockcore Reference Nodes"}, {"location": "release-process/#blockcore-indexer", "text": "6: https://github.com/block-core/blockcore-indexer Add any new network NuGet packages, if new blockchains has been added. When the draft release is published, the workflow will automatically build and publish container images to Docker Hub. Image: https://hub.docker.com/repository/docker/blockcore/indexer", "title": "Blockcore Indexer"}, {"location": "release-process/#blockcore-explorer", "text": "7: https://github.com/block-core/blockcore-explorer Update the version, also verify if there is any NPM packages that should be updated on the UI project. When the draft release is published, the workflow will automatically build and publish container images to Docker Hub. The Explorer does not depend on the network NuGet packages and does not need to be updated for every new blockchain. Image: https://hub.docker.com/repository/docker/blockcore/explorer", "title": "Blockcore Explorer"}, {"location": "release-process/#blockcore-tipbot", "text": "8: https://github.com/block-core/blockcore-tipbot The TipBot is hosted by Blockcore as a community service, but we advice teams to use their own dedicated tipbot for individual blockchains. The TipBot does not depend on the network NuGet packages and does not need to be updated for every new blockchain.", "title": "Blockcore TipBot"}, {"location": "release-process/#blockcore-hub", "text": "9: https://github.com/block-core/blockcore-hub Blockcore Hub requires that the multi-node to be released first, it embeds the full node software. Upgrade packages and version, then publish the draft release after build is complete.", "title": "Blockcore Hub"}, {"location": "release-process/#chains-configurations", "text": "10: https://github.com/block-core/chaininfo The Blockcore software utilizes an hosted server for configuration. This makes it possible to update configurations of software without re-installations and updated releases. It is the responsibility of individual blockchains to maintain their own configurations, but the Blockcore team will support and help with instructions. The configurations are published on the website: https://chains.blockcore.net/", "title": "Chains configurations"}, {"location": "securityissues/", "text": "Responsible Disclosure of Security Issues If you discover, or think you have found, a potential security issue with either Blockcore, supporting technologies or any blockchain built on Blockcore technologies, please make sure you report the security issue in a responsible disclosure. Please report security issues by e-mail, to the address provided at the Blockcore website . You will find the PGP finger-print at the bottom of the website. We thank you for your consideration in reporting any security issues in a responsible and timely manner, allowing the developers to fix the bugs and problems before they result in serious issues for our users.", "title": "Security issues"}, {"location": "securityissues/#responsible-disclosure-of-security-issues", "text": "If you discover, or think you have found, a potential security issue with either Blockcore, supporting technologies or any blockchain built on Blockcore technologies, please make sure you report the security issue in a responsible disclosure. Please report security issues by e-mail, to the address provided at the Blockcore website . You will find the PGP finger-print at the bottom of the website. We thank you for your consideration in reporting any security issues in a responsible and timely manner, allowing the developers to fix the bugs and problems before they result in serious issues for our users.", "title": "Responsible Disclosure of Security Issues"}, {"location": "signingcommits/", "text": "Signing commits We would appricate that all commits to Blockcore be signed by the contributors. Windows Install GPG4Win Run Kleopatra Generate a key, preferably 4096 bytes. Avoid pass phrase if you don't want to supply it on every commit or use tools to cache it locally. Fill out your details, name and e-mail. The e-mail must be a verified address on Github, or your no-reply address on Github. Find your key by opening cmd.exe 1 gpg --list-secret-keys --keyid-format LONG Above command will return your keys, starting with their strength and then ID. Make sure you use the \"sec\" key and not the \"ssb\" key. \"sec\" is for Certify and Signing, the \"ssb\" is for Encrypting. Depending on your environment variables, cmd and git bash will store keys in different locations. Kleopatra will put keys in the location that cmd.exe looks at. cmd.exe: C:\\Users\\USER\\AppData\\Roaming\\gnupg git bash: C:\\Users\\USER.gnupg To fix this, open git bash and search for pgb: 1 where gpg Copy the path that goes to the recent GnuPG folder, for example: 1 C:\\Program Files (x86)\\GnuPG\\bin\\gpg.exe Then create a new file, if it doesn't exists, under your user profile (C:\\Users\\USER\\.bash_profile) named .bash_profile and fill out this into the file: 1 alias gpg=\"'C:\\Program Files (x86)\\GnuPG\\bin\\gpg.exe'\" Then run the same gpg command to list keys, and you should see same result in cmd and git bash. Configure git repo to always sign. You can do this globally with the flag --global if you want to. 1 2 3 # Local only git config user.signingkey KEYID git config commit.gpgsign true 1 2 3 # Globally git config --global user.signingkey KEYID git config --global commit.gpgsign true You might also want to inform git to use the custom GPG you installed and not the one included with for example Github Desktop: 1 git config --global gpg.program \"C:\\Program Files (x86)\\GnuPG\\bin\\gpg.exe\" Get your public key: 1 gpg --armor --export KEYID Add your Public Key to Github . Linux TBA Addtional links Signing commits by Github How to enable auto-signing Git commits with GnuPG for programs that don't support it natively Since git 2.19.1, gpg2 is supported!", "title": "Signing commits"}, {"location": "signingcommits/#signing-commits", "text": "We would appricate that all commits to Blockcore be signed by the contributors.", "title": "Signing commits"}, {"location": "signingcommits/#windows", "text": "Install GPG4Win Run Kleopatra Generate a key, preferably 4096 bytes. Avoid pass phrase if you don't want to supply it on every commit or use tools to cache it locally. Fill out your details, name and e-mail. The e-mail must be a verified address on Github, or your no-reply address on Github. Find your key by opening cmd.exe 1 gpg --list-secret-keys --keyid-format LONG Above command will return your keys, starting with their strength and then ID. Make sure you use the \"sec\" key and not the \"ssb\" key. \"sec\" is for Certify and Signing, the \"ssb\" is for Encrypting. Depending on your environment variables, cmd and git bash will store keys in different locations. Kleopatra will put keys in the location that cmd.exe looks at. cmd.exe: C:\\Users\\USER\\AppData\\Roaming\\gnupg git bash: C:\\Users\\USER.gnupg To fix this, open git bash and search for pgb: 1 where gpg Copy the path that goes to the recent GnuPG folder, for example: 1 C:\\Program Files (x86)\\GnuPG\\bin\\gpg.exe Then create a new file, if it doesn't exists, under your user profile (C:\\Users\\USER\\.bash_profile) named .bash_profile and fill out this into the file: 1 alias gpg=\"'C:\\Program Files (x86)\\GnuPG\\bin\\gpg.exe'\" Then run the same gpg command to list keys, and you should see same result in cmd and git bash. Configure git repo to always sign. You can do this globally with the flag --global if you want to. 1 2 3 # Local only git config user.signingkey KEYID git config commit.gpgsign true 1 2 3 # Globally git config --global user.signingkey KEYID git config --global commit.gpgsign true You might also want to inform git to use the custom GPG you installed and not the one included with for example Github Desktop: 1 git config --global gpg.program \"C:\\Program Files (x86)\\GnuPG\\bin\\gpg.exe\" Get your public key: 1 gpg --armor --export KEYID Add your Public Key to Github .", "title": "Windows"}, {"location": "signingcommits/#linux", "text": "TBA", "title": "Linux"}, {"location": "signingcommits/#addtional-links", "text": "Signing commits by Github How to enable auto-signing Git commits with GnuPG for programs that don't support it natively Since git 2.19.1, gpg2 is supported!", "title": "Addtional links"}, {"location": "support/", "text": "Support This project is open source, and is not a company. Instead we rely on a network of contributors and users to provide support. Free support Problem? Don't worry, someone else has probably been through that before you. First have a look at our user documentation and Frequently Asked Questions . If your issue is not referenced there, or you want to request a new feature, please open a github issue . If you have more general questions about Blockcore, the way it works and why you should use it, you're welcome on our Discord Getting a proper support also depends on how you formulate your questions. Read our troubleshooting guidelines . Paid support Here are some members of the community that you can contact to get additional paid support: Sondre Bjell\u00e5s (SondreB) I can assist with your Blockcore journey. I develop custom features for full node, indexer, explorer, wallet and more. Some of the features I can help with are: New blockchain, New Apis, Client Libraries, Custom Apps, Docker Functionality etc. Contact: sondre@blockcore.net, Twitter , LinkedIn", "title": "Support"}, {"location": "support/#support", "text": "This project is open source, and is not a company. Instead we rely on a network of contributors and users to provide support.", "title": "Support"}, {"location": "support/#free-support", "text": "Problem? Don't worry, someone else has probably been through that before you. First have a look at our user documentation and Frequently Asked Questions . If your issue is not referenced there, or you want to request a new feature, please open a github issue . If you have more general questions about Blockcore, the way it works and why you should use it, you're welcome on our Discord Getting a proper support also depends on how you formulate your questions. Read our troubleshooting guidelines .", "title": "Free support"}, {"location": "support/#paid-support", "text": "Here are some members of the community that you can contact to get additional paid support:", "title": "Paid support"}, {"location": "support/#sondre-bjellas-sondreb", "text": "I can assist with your Blockcore journey. I develop custom features for full node, indexer, explorer, wallet and more. Some of the features I can help with are: New blockchain, New Apis, Client Libraries, Custom Apps, Docker Functionality etc. Contact: sondre@blockcore.net, Twitter , LinkedIn", "title": "Sondre Bjell\u00e5s (SondreB)"}, {"location": "usecases/", "text": "Built with the community in mind, Blockcore is a feature-rich software with plenty of use-cases that can solve problems for different types of users. The software usage is by no means limited to the groups of users mentioned in this document. Merchants Self-sovereign individuals Cryptocurrency Exchanges Hosting Providers Developers", "title": "Use Cases"}, {"location": "usecases/#merchants", "text": "", "title": "Merchants"}, {"location": "usecases/#self-sovereign-individuals", "text": "", "title": "Self-sovereign individuals"}, {"location": "usecases/#cryptocurrency-exchanges", "text": "", "title": "Cryptocurrency Exchanges"}, {"location": "usecases/#hosting-providers", "text": "", "title": "Hosting Providers"}, {"location": "usecases/#developers", "text": "", "title": "Developers"}, {"location": "walkthrough/", "text": "Walkthrough making your own blockchain Follow these steps to successfully start your own blockchain. 1. Use the software generator Begin by visiting our wizard and generator that is located on our main website: https://www.blockcore.net/create-chain When all of that is completed, you have the software needed to start your blockchain. 2. Get your initial pre-mine address First step you need to perform is getting the receive address you can use to perform the initial mining on your blockchain. Either you can launch the Node UI on the TCP port you specificed, or you can use the REST API . The URL for your Node UI is shown in the startup of the node, like shown in this screenshot: First step is to make yourself a new wallet. You can do this without having any connections to other nodes. After creating a wallet, make sure you protect your recovery phrase. If this is lost or shared, you can loose access to the funds. Go to \"Wallets\" then \"Details\" on your wallet. Then click the \"Receive\" button on top right. An valid address for your wallet will now be displayed. Copy this address for the next step. 3. Mining and Staking When you first start a new blockchain, you need to perform Proof-of-Work mining. This can easily be done using a basic CPU on your computer, no need for expensive hardware. Find your \"network.conf\" file and enable the following settings. Configuration file is normally located under a path like this on Windows: C:\\Users\\USER\\AppData\\Roaming\\Blockcore\\YOURNETWORK\\YourNetworkMain 1 2 3 4 5 6 7 8 9 10 11 ####Miner Settings#### #Enable POW mining. mine=1 #Enable POS. stake=1 #The address to use for mining (empty string to select an address from the wallet). mineaddress=PASTE_ADDRESS_FROM_STEP_2 #The wallet name to use when staking. walletname=NAME_OF_YOUR_WALLET #Password to unlock the wallet. walletpassword=YOUR_WALLET_PASSWORD 4. Connect to other nodes You cannot send transactions unless you have one or more connections. Additionally all new coins must be matured before you can send them. Initially it is required that new coins must be 50 blocks deep, and later on the requirement is 500. This can be configured in code. You can launch two nodes locally, by changing the default ports on one of the instances. Use the following settings, with some modifications, to launch two instances of your node software: launch-first.bat 1 \"C:\\src\\github\\blockcore\\blockcore\\src\\Node\\Blockcore.Node\\bin\\Debug\\netcoreapp3.1\\Blockcore.Node.exe\" --chain=YOURNETWORK -server -listen=1 -maxtipage=2147483647 -iprangefiltering=0 -apiport=10011 -whitelist=YOUR_LAN_IP -server=1 -rpcport=10010 -rpcallowip=127.0.0.1 -rpcbind=127.0.0.1 -rpcpassword=rpcpassword -rpcuser=rpcuser -datadir=nodedata1 launch-second.bat: 1 \"C:\\src\\github\\blockcore\\blockcore\\src\\Node\\Blockcore.Node\\bin\\Debug\\netcoreapp3.1\\Blockcore.Node.exe\" --chain=YOURNETWORK -server -listen=1 -maxtipage=2147483647 -iprangefiltering=0 -apiport=10021 -addnode=YOUR_LAN_IP -rpcport=10020 -rpcallowip=127.0.0.1 -rpcbind=127.0.0.1 -rpcpassword=rpcpassword -rpcuser=rpcuser -datadir=nodedata2 Explaination of parameters: -server=1: This will make one node listen for incoming connections on the default p2p port. -addnode: This will connect to the other node on startup. -iprangefiltering=0: This will allow connection between local LAN nodes. 5. Next steps For the next steps, you can begin to integrate the Indexer, Explorer, Extension or other software in the Blockcore Platform. If you add your custom network to the chains repository, then the Blockcore Platform will automatically support your network more easily without forking. https://github.com/block-core/chaininfo", "title": "Walkthrough"}, {"location": "walkthrough/#walkthrough-making-your-own-blockchain", "text": "Follow these steps to successfully start your own blockchain.", "title": "Walkthrough making your own blockchain"}, {"location": "walkthrough/#1-use-the-software-generator", "text": "Begin by visiting our wizard and generator that is located on our main website: https://www.blockcore.net/create-chain When all of that is completed, you have the software needed to start your blockchain.", "title": "1. Use the software generator"}, {"location": "walkthrough/#2-get-your-initial-pre-mine-address", "text": "First step you need to perform is getting the receive address you can use to perform the initial mining on your blockchain. Either you can launch the Node UI on the TCP port you specificed, or you can use the REST API . The URL for your Node UI is shown in the startup of the node, like shown in this screenshot: First step is to make yourself a new wallet. You can do this without having any connections to other nodes. After creating a wallet, make sure you protect your recovery phrase. If this is lost or shared, you can loose access to the funds. Go to \"Wallets\" then \"Details\" on your wallet. Then click the \"Receive\" button on top right. An valid address for your wallet will now be displayed. Copy this address for the next step.", "title": "2. Get your initial pre-mine address"}, {"location": "walkthrough/#3-mining-and-staking", "text": "When you first start a new blockchain, you need to perform Proof-of-Work mining. This can easily be done using a basic CPU on your computer, no need for expensive hardware. Find your \"network.conf\" file and enable the following settings. Configuration file is normally located under a path like this on Windows: C:\\Users\\USER\\AppData\\Roaming\\Blockcore\\YOURNETWORK\\YourNetworkMain 1 2 3 4 5 6 7 8 9 10 11 ####Miner Settings#### #Enable POW mining. mine=1 #Enable POS. stake=1 #The address to use for mining (empty string to select an address from the wallet). mineaddress=PASTE_ADDRESS_FROM_STEP_2 #The wallet name to use when staking. walletname=NAME_OF_YOUR_WALLET #Password to unlock the wallet. walletpassword=YOUR_WALLET_PASSWORD", "title": "3. Mining and Staking"}, {"location": "walkthrough/#4-connect-to-other-nodes", "text": "You cannot send transactions unless you have one or more connections. Additionally all new coins must be matured before you can send them. Initially it is required that new coins must be 50 blocks deep, and later on the requirement is 500. This can be configured in code. You can launch two nodes locally, by changing the default ports on one of the instances. Use the following settings, with some modifications, to launch two instances of your node software: launch-first.bat 1 \"C:\\src\\github\\blockcore\\blockcore\\src\\Node\\Blockcore.Node\\bin\\Debug\\netcoreapp3.1\\Blockcore.Node.exe\" --chain=YOURNETWORK -server -listen=1 -maxtipage=2147483647 -iprangefiltering=0 -apiport=10011 -whitelist=YOUR_LAN_IP -server=1 -rpcport=10010 -rpcallowip=127.0.0.1 -rpcbind=127.0.0.1 -rpcpassword=rpcpassword -rpcuser=rpcuser -datadir=nodedata1 launch-second.bat: 1 \"C:\\src\\github\\blockcore\\blockcore\\src\\Node\\Blockcore.Node\\bin\\Debug\\netcoreapp3.1\\Blockcore.Node.exe\" --chain=YOURNETWORK -server -listen=1 -maxtipage=2147483647 -iprangefiltering=0 -apiport=10021 -addnode=YOUR_LAN_IP -rpcport=10020 -rpcallowip=127.0.0.1 -rpcbind=127.0.0.1 -rpcpassword=rpcpassword -rpcuser=rpcuser -datadir=nodedata2 Explaination of parameters: -server=1: This will make one node listen for incoming connections on the default p2p port. -addnode: This will connect to the other node on startup. -iprangefiltering=0: This will allow connection between local LAN nodes.", "title": "4. Connect to other nodes"}, {"location": "walkthrough/#5-next-steps", "text": "For the next steps, you can begin to integrate the Indexer, Explorer, Extension or other software in the Blockcore Platform. If you add your custom network to the chains repository, then the Blockcore Platform will automatically support your network more easily without forking. https://github.com/block-core/chaininfo", "title": "5. Next steps"}, {"location": "decentralization/social-media/social-media-platforms/", "text": "What Does it Mean to be a Decentralized Social Media Platform? Articulating first principles as a means to discover requirements towards a social media platform The Goal Imagine a decentralized social media platform that was as ubiquitous as Bitcoin, that no group or government could shut down (without shutting down the internet), where no authority, large or small, could prevent a person from speaking. A Decentralized Social Media Platform Sounds great, but what does it mean? Does the ability to spin up a server and provide a web U.I. constitute a \"decentralized\" server? In the original sense of the early internet, where any person could connect their computer to the internet, publish that machine's I.P. Address, and listen on port 80, then yes, in this sense, it is a genuinely decentralized social media web application. That's fine. As far as it goes. Let's call it the SoapBox Platform idea. Every person with the technical know-how can set up their own soapbox. But what about the plebs, those without the expertise to do this? In the first days of the internet, a person would set up a webserver to publish their website and then speak with that voice on the internet. There was a one-to-one mapping of speech to person (reminder: the U.S. Supreme Court ruled that a corporation is a person, and money is speech). Let's imagine a land with a political system whereby only land-owners could vote or where only their voice could be heard in the public space. Now, let's say one person owns all the land, so there is only one vote that matters. This is a fair analogy to the Soapbox platform. The soapbox owners control the speech of that platform because they control who can speak, and therefore they control all the speech. In a nutshell, countering this type of centralized control is the psychological driver behind the decentralization movement on the internet. Over the last few years, disposition, portability, interoperability , functionality , data , and identity have emerged as critical elements of decentralization. TANSTAAFL - \"There Ain't No Such Thing As A Free Lunch\" - Robert Heinlein, The Moon Is A Harsh Mistress Today\u2019s social media platforms sustain their operation through productizing the user. The ability to productize the user is a direct consequence of centralized control over all actions on the platform. The trade-off for the user is that they have \"free\" access. In exchange for the market analysis tracking the user's activities, the platform can direct advertisements to the user they will most likely find interesting. This produces the revenue model that supports and sustains the platform . This mechanism seems somewhat innocuous on its face, but consider that it can be aimed at the sphere of political activity on social media. This is evidenced by Facebook's use of these algorithms in the 2016 U.S. Presidential Election to promote heated and adversarial political arguments on their platform to socially engineer more clicks resulting in a deep political polarization in the U.S. This is where centralized control of speech becomes nasty. And it suggests that the productization of the user may not be the best means of funding for a decentralized social media platform. And yet some means of funding is necessary. TANSTAAFL ! Requirements So let's make a list of requirements a social media platform must have to be considered decentralized. We can then use this list to construct a scorecard to assess how decentralized a platform is. Disposition What and where is the server(s)? Are they behind a single Domain Name representing a single entity? If that is the case, then they are considered centralized. 1. Distributed servers : the physical disposition of the servers must be distributed across a network so that they cannot be controlled by a single entity or \"oligarchy.\" This should ensure that owner(s) cannot shut down the soapbox. Functionality In a decentralized network of servers, how does the functionality get deployed over time? This is a tricky problem. Bitcoin, Ethereum, and other cryptocurrencies have varied strategies to upgrade server nodes over time. And Ethereum and other blockchains have introduced dApps, distributed applications, to expose new functionality on the network. A Decentralized Social Media Platform will face the same problems. 2. Functionality : Application Logic must be deployable and upgradable across the decentralized network. Data Concepts surrounding data on a decentralized social media network are complex and multi-dimensional. Data could be meta-data (list of followers/friends/blocks), messages, posts, images, videos, etc. But one idea that is universally accepted in the decentralized (Self-Sovereign) community is that a person owns their data. This means that each person has complete control of their data. But there is more to think about concerning data on a decentralized network. Such as storage which, again, is another complicated topic. And, once users put data on that server, can they be locked out or banned from that server? If so, this is also a consequence of centralization because users cannot take their data (which might include a list of their friends/followers) and move it to another platform. In other words, the data is not portable. For now, we can articulate these requirements: 3. Data Ownership : Each platform user must have complete control of their data. 4. Data Storage : must be stored and retrieved from a distributed decentralized network of storage containers. 5. Portability and Interoperability : the user must have the means to take their data and move to another soapbox. Identity So we have a requirement for complete ownership of a user's data by that user . But who is that user? To ensure ownership of an artifact, we must have a way to verify and validate a user's claims of identity. Identity is a central theme around the concept of access , also. This is because access is necessary for speech on a given platform. How can we handle identity in a decentralized way that does not rely on a centralized entity? Access is also tied to the idea of ownership and control. When users are asked to show their identity, can they show artifacts proving identity that do not require mediation through a centralized authority? In other words, can a person prove who they are without relying on a 3rd party to say who they are? What if that 3rd Party is compromised somehow or disappears altogether? On a decentralized social media platform, identity is a crucial concept that underpins all human interactions on a decentralized platform. These are hot topics in the Self-Sovereign community, but we can state this requirement for now. 6. Identity : A user must have complete control over and access to the mechanism that proves their claims of who they are. Support and Sustainment The revenue model of today's leading social media platforms, productization of the user, as means for support and sustainment of the platform is not in the best interest of the platform's users. But it costs money to support any kind of computer network. So what other means of support might be devised in a decentralized way? We don't need to look far for a solution. This is what crypto-currencies do, provide a means of support for their underlying blockchain network. Details matter here. Types of crypto-currencies are delineated by their consensus algorithms. Two well-known consensus algorithms are Proof of Work and Proof of Stake. We won't get into the details of that rabbit hole just yet, except to say that the more aligned the consensus algorithm is to the platform's mission, the greater the chance of success. For now, let's state the requirement. 7. Support and Sustainment : The platform must provide a built-in, decentralized means of sustainment through a crypto-currency mechanism that aligns with and supports the platform's mission.", "title": "Social media platforms"}, {"location": "decentralization/social-media/research-and-design/reading-list/", "text": "General Reading List an aid to understand the emerging culture of decentralization The Bitcoin Standard: The Decentralized Alternative to Central Banking by Saifedean Ammous https://www.amazon.com/Bitcoin-Standard-Decentralized-Alternative-Central/dp/1119473861 What else? Let's keep this list on topic . Stratis is based on the Blockcore source code, and has excellent documentation to help explain much of the Bockcore architecture, as well: https://academy.stratisplatform.com/Architecture%20Reference/architecture-reference-introduction.html", "title": "Reading list"}, {"location": "decentralization/social-media/research-and-design/readme/", "text": "Research and Design Notes and Thoughts I plan to put the architecture diagram here summarizing the R&D. coming soon", "title": "Readme"}, {"location": "decentralization/social-media/research-and-design/consensus-algorithms/dPos/", "text": "Article to discuss Delegated Proof of Stake, and how to modify the algorithm to also do work for the platform (once we've defined that work.)", "title": "dPos"}, {"location": "decentralization/social-media/research-and-design/dApps/nostr/", "text": "nostr \" The simplest open protocol that is able to create a censorship-resistant global \"social\" network once and for all. It doesn't rely on any trusted central server, hence it is resilient; it is based on cryptographic keys and signatures, so it is tamperproof; it does not rely on P2P techniques, therefore it works. \" - fiatjaf Telegram Forum : https://t.me/nostr_protocol GitHub : https://github.com/fiatjaf/nostr nostr protocol implemented in DotNet https://github.com/Kukks/NNostr Fascinating Interview with nostr developers: https://bitcointv.com/w/3uDQAViaQShdphUzY4mmtC and a less choppy version here: https://open.spotify.com/show/2KmZgeZUC1trxOvDvfQefy Note: This protocol is under consideration for implementation in this project.", "title": "Nostr"}, {"location": "decentralization/social-media/research-and-design/dApps/stratis.cirrus/", "text": "Is Stratis Cirrus Sidechains and C# Smart Contracts a suitable architecture for a decentralized social media use case? What is the feedback from the Blockcore team?", "title": "Stratis.cirrus"}, {"location": "decentralization/social-media/research-and-design/dApps/taarafo/", "text": "Taarafo: Engineering Free Speech https://www.youtube.com/playlist?list=PLan3SCnsISTQNkgtVMqJu896TghXjGYzt Hassan Habib's objectives align well with our objectives to build a fully decentralized social media platform. His current codebase, let's be honest, is centralized. He knows it. And he states here his intention to fulling decentralize a user's content and shares his thoughts on how he might do it. https://www.youtube.com/watch?v=ZGov4vuGj8A&list=PLan3SCnsISTQNkgtVMqJu896TghXjGYzt&t=2523s Contrary to the video, it is not technically feasible to give each user their own blockchain like Bitcoin or Ethereum because a) each user would need a node network that is talking to all the other user's node networks, and so on, and b) that type of blockchain is specifically designed to defend against the \"double-spend\" and similar types of issues concerning decentralized money , and a social media platform is a much simpler use case. However, in recent years, a new type of chained hash ledger design has emerged that is just as cryptographically secure as a traditional blockchain, and that is KERI. (warning: Rabbit Hole!) see my notes on that in the KERI file. Self-Certification of Identifiers is the innovation. Here, suffice to say that each user could store their Keys in a KERI-like ledger and store their social activity content in a similar log. KERI ledgers do not need to be deployed to a distributed network because they do not need a consensus mechanism for validation. Because each identifier in the ledger is self-certifying . So yes, Hassan's idea is feasible if we tweak it just a little bit. I think we may be able to use cloud and/or IPFS type storage (see other note). But, we need to step back and look at all of the technologies that we can bring to bear on the problem to come up with the most practical solution.", "title": "Taarafo"}, {"location": "decentralization/social-media/research-and-design/dApps/x42/", "text": "Question: Can X42's new capability of supporting any application stored in a docker file? Will the X42 scheme work with a Blazor WASM and/or Blazor Server App? What do the developers say? Answer: The word from X42\u2019s SaVa is : \u201cBasically if it can run in Docker, it can run on the xServer network \u2026 any application that can be containerized can be hosted on x42 xServers. We are releasing WordPress preview on the 1st of June.\u201d", "title": "X42"}, {"location": "decentralization/social-media/research-and-design/data/readme/", "text": "This directory is intended for the discussion of distributed data issues. Any relevant diagrams can go in this document.", "title": "Readme"}, {"location": "decentralization/social-media/research-and-design/data/architecture/strategy/", "text": "Strategy and Tactics for Decentralized Data Storage and Retrieval The purpose of this document is to identify decentralized strategy and tactics for storage and retrieval of data files. First Idea. Use Filebase's S3 Compatible interface (backed by IPFS and Sia) to provide a clean API for the decentralized storage and retrieval of files IPFS - The Interplanetary File System : https://ipfs.io/#why FileBase : https://blog.ipfs.io/2022-04-14-filebase/ What is FileBase? https://docs.filebase.com/what-is-filebase/master \u201cFilebase is the first S3-compatible object storage platform that allows you to store data in a secure, redundant, and performant manner across multiple decentralized storage networks.\u201d Note: Filebase is offering the first five gigabytes of storage for free. Which means that we can create a contraint on our file cache to always delete the oldest files when the cache size nears the free data limit. This is a tactic to get our decentralized storage up and running. The user would register an account through our platform and be able directly own and control all their data with no centralized intermediary. The message and data they share on the platform would be in the form of S3 links to their data.", "title": "Strategy"}, {"location": "decentralization/social-media/research-and-design/data/models/models/", "text": "We need to develop a standard for social media data models covering at a minimum: Facebook, Instagram, Twitter, Linkedin and Reddit", "title": "Models"}, {"location": "decentralization/social-media/research-and-design/identity/keri/", "text": "KERI: Key Event Registry Infrastructure \"KERI is the first truly decentralized identity system. It is ledger-less, so it doesn't need to use a ledger or is ledger-portable. Its identifiers are not locked to any given ledger and may switch as needed. In other words, KERI identifiers are genuinely portable. KERI is inherently supportive of GDPR (global data protection rights) compliance. KERI provides non-intertwined identifier trust bases, meaning that a given identifier's data may be erased and truly forgotten. KERI has a decentralized, secure root-of-trust based on cryptographic self-certifying identifiers. It has separable control over shared data which means each entity is truly self-sovereign over its identifiers. It uses hash-chained data structures called Key Event Logs that enable ambient cryptographic verifiability. In other words, any log may be verified anywhere at anytime by anybody.\" KERI Website: https://keri.one/ The White Paper : https://github.com/SmithSamuelM/Papers/blob/master/whitepapers/KERI_WP_2.x.web.pdf SSI-Meetup https://ssimeetup.org/key-event-receipt-infrastructure-keri-secure-identifier-overlay-internet-sam-smith-webinar-58/ SSI Meetup Presentation : https://www.youtube.com/watch?v=izNZ20XSXR0 SSI Meetup Slides : https://docs.google.com/presentation/d/1HvDSdMFLAuTMlgPoQ4y6UlgfTA3zziRlChNsV7MuprY/edit?usp=sharing GitHub : https://github.com/orgs/WebOfTrust/repositories?type=all Rust Implementation : https://github.com/WebOfTrust/keriox Composable Event Streaming Representation (CESR) https://weboftrust.github.io/ietf-cesr/draft-ssmith-cesr.html KERI.DotNet I am particularly interested in the Rust implementation of KERI. It would be great if we could put a DotNet wrapper around that library. Thoughts?", "title": "Keri"}, {"location": "decentralization/social-media/research-and-design/identity/self-sovereign/", "text": "Reading List : This document aims to track promising ideas that address the problem of (self-sovereign) identity in a Decentralized Social Media Platform. The Bible on Self-Sovereign Identity: https://www.manning.com/books/self-sovereign-identity Covers all aspects of state of the art of research on decentralized identity, from verifiable credentials, to decentralized IDs and self-verifying identifiers, to Key Event Log Registry Infrastructure (KERI), this book covers it all. Highly recommended to anyone wanting to understand this space. Let's keep this list on on topic. A good overview of The Decentralized Identity Foundation: https://identity.foundation/faq/", "title": "Self sovereign"}, {"location": "decentralization/social-media/research-and-design/laws/gdpr/", "text": "The GDPR https://en.wikipedia.org/wiki/General_Data_Protection_Regulation \" The GDPR's primary aim is to enhance individuals' control and rights over their personal data and to simplify the regulatory environment for international business.\" These regulations are in harmony with our goals to give the user complete control over their data. Of particular interest is the \"Right to be forgotten.\" This means that users have the right to delete themselves from a public database. I think this is crucial, and we need to think carefully about implementing it. Obviously, if a user or its data were written to a public blockchain, their public keys are permanently there. So how does one \"forget\" a thing that cannot be deleted. KERI has a solution to that. See KERI.", "title": "Gdpr"}, {"location": "example-projects/", "text": "The best way to see it in action is by inspecting the Example projects I've created. It's a multi-project example where each project plays its role into the modular application architecture. Its goal is to show how to make use of Mithril Shards to implement a P2P application that implements a custom Web API controller, a custom network implementation and its own protocol with custom messages and serializators. It reuses some other standard shards like : [BedrockNetworkShard] [StatisticCollectorShard] [SerilogShard] [WebApiShard] [DevControllerShard] What it does is quite simple: You can run two instance of this project to connect to each other and every 10 seconds a ping message will be sent to the other peer, with a random quote message. The quote message is randomly picked by the QuoteService and quotes can be manipulated by using the ExampleController exposed by the Web API . Example Projects The example is composed by several projects, each one with their own scope, to mimic a (simple) typical modular application: MithrilShards.Example MithrilShards.Example.Network.Bedrock MithrilShards.Example.Dev MithrilShards.Example.Node Each project has its own documentation page to present its purpose and to explain some implementation details, however all the code is well commented so you shouldn't have any problems understanding it, in any case the Discussions on my repository is open for you.", "title": "Example Projects Overview"}, {"location": "example-projects/#example-projects", "text": "The example is composed by several projects, each one with their own scope, to mimic a (simple) typical modular application: MithrilShards.Example MithrilShards.Example.Network.Bedrock MithrilShards.Example.Dev MithrilShards.Example.Node Each project has its own documentation page to present its purpose and to explain some implementation details, however all the code is well commented so you shouldn't have any problems understanding it, in any case the Discussions on my repository is open for you.", "title": "Example Projects"}, {"location": "example-projects/mithril-shards-example-dev/", "text": "MithrilShards.Example.Dev Contains just a Controller that expose a couple of Web API actions to manipulate the QuoteService and list, add and remove quotes. In order to show an alternative way to register controllers, this project doesn't implement a shard and doesn't have any Add* / Use* extension method to add its share, instead its controller is discovered using the ControllersSeeker property of [WebApiShard] in its UseApi extension method..", "title": "MithrilShards.Example.Dev"}, {"location": "example-projects/mithril-shards-example-dev/#mithrilshardsexampledev", "text": "Contains just a Controller that expose a couple of Web API actions to manipulate the QuoteService and list, add and remove quotes. In order to show an alternative way to register controllers, this project doesn't implement a shard and doesn't have any Add* / Use* extension method to add its share, instead its controller is discovered using the ControllersSeeker property of [WebApiShard] in its UseApi extension method..", "title": "MithrilShards.Example.Dev"}, {"location": "example-projects/mithril-shards-example-network-bedrock/", "text": "MithrilShards.Example.Network.Bedrock Contains few classes that are implementing the INetworkProtocolMessageSerializer interface needed by the [BedrockNetworkShard] shard to perform message serialization. In this example we are mimicking bitcoin protocol that uses a magic word (4 bytes) that mark the start of a new message and it's message layout to define the rule to decode and encode messages over the network (see ProtocolDefinition.cs file). Note how the code is really small and how it's easy to define custom network serialization of messages. Current implementation relies on Bedrock framework shard, but if you want to create another lol level network implementation you are free to do so, you don't have to change anything else except this project to make use of your new low level network protocol, everything is abstracted out in the Mithril Shards Core project!!", "title": "MithrilShards.Example.Network.Bedrock"}, {"location": "example-projects/mithril-shards-example-network-bedrock/#mithrilshardsexamplenetworkbedrock", "text": "Contains few classes that are implementing the INetworkProtocolMessageSerializer interface needed by the [BedrockNetworkShard] shard to perform message serialization. In this example we are mimicking bitcoin protocol that uses a magic word (4 bytes) that mark the start of a new message and it's message layout to define the rule to decode and encode messages over the network (see ProtocolDefinition.cs file). Note how the code is really small and how it's easy to define custom network serialization of messages. Current implementation relies on Bedrock framework shard, but if you want to create another lol level network implementation you are free to do so, you don't have to change anything else except this project to make use of your new low level network protocol, everything is abstracted out in the Mithril Shards Core project!!", "title": "MithrilShards.Example.Network.Bedrock"}, {"location": "example-projects/mithril-shards-example-node/", "text": "MithrilShards.Example.Node It makes use of System.CommandLine to have implement the application as a CLI . While all other projects were C# Class Library projects, this one produces an executable that's the actual, assembled application. It contains the Program.cs file that melt the shards into the forge and run it, plus a couple of configuration files that you can inspect to see different configuration combinations. Program.cs file is quote short and easy to read: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 using System.CommandLine ; using System.CommandLine.Invocation ; using System.Threading.Tasks ; using MithrilShards.Core.Forge ; using MithrilShards.Dev.Controller ; using MithrilShards.Diagnostic.StatisticsCollector ; using MithrilShards.Example.Dev ; using MithrilShards.Example.Network.Bedrock ; using MithrilShards.Example.Protocol ; using MithrilShards.Logging.Serilog ; using MithrilShards.Network.Bedrock ; using Serilog ; namespace MithrilShards.Example.Node { static class Program { static async Task Main ( string [] args ) { // Create a root command with some options var rootCommand = new RootCommand { new Option < string >( \"--settings\" , getDefaultValue : () => \"forge-settings.json\" , description : \"Specify the path to the forge settings file.\" ), new Option < string? >( \"--log-settings\" , getDefaultValue : () => null , description : \"Specify the path to the forge log settings file. If not specified, try to get logging information from the main forge settings file.\" ), new Option < int >( \"--protocol-version\" , getDefaultValue : () => KnownVersion . CurrentVersion , description : \"Specify the path to the forge settings file.\" ) }; rootCommand . Description = \"Example App\" ; rootCommand . TreatUnmatchedTokensAsErrors = false ; // Note that the parameters of the handler method are matched according to the names of the options rootCommand . Handler = CommandHandler . Create < string , string , int >( async ( settings , logSettings , protocolVersion ) => { await new ForgeBuilder () . UseForge < DefaultForge >( args , settings ) . UseSerilog ( logSettings ) . UseBedrockNetwork < ExampleNetworkProtocolMessageSerializer >() . UseStatisticsCollector ( options => options . DumpOnConsoleOnKeyPress = true ) /// we are injecting ExampleDev type to allow <see cref=\"MithrilShards.WebApi.WebApiShard\"/> to find all the controllers /// defined there because only controllers defined in an included shard assemblies are discovered automatically. /// Passing ExampleDev will cause dotnet runtime to load the assembly where ExampleDev Type is defined and every /// controllers defined there will be found later during <see cref=\"MithrilShards.WebApi.WebApiShard\"/> initialization. . UseApi ( options => options . ControllersSeeker = ( seeker ) => seeker . LoadAssemblyFromType < ExampleDev >()) . UseDevController () . UseExample ( KnownVersion . V1 , protocolVersion ) . RunConsoleAsync () . ConfigureAwait ( false ); }); await rootCommand . InvokeAsync ( args ). ConfigureAwait ( false ); } } }", "title": "MithrilShards.Example.Node"}, {"location": "example-projects/mithril-shards-example-node/#mithrilshardsexamplenode", "text": "It makes use of System.CommandLine to have implement the application as a CLI . While all other projects were C# Class Library projects, this one produces an executable that's the actual, assembled application. It contains the Program.cs file that melt the shards into the forge and run it, plus a couple of configuration files that you can inspect to see different configuration combinations. Program.cs file is quote short and easy to read: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 using System.CommandLine ; using System.CommandLine.Invocation ; using System.Threading.Tasks ; using MithrilShards.Core.Forge ; using MithrilShards.Dev.Controller ; using MithrilShards.Diagnostic.StatisticsCollector ; using MithrilShards.Example.Dev ; using MithrilShards.Example.Network.Bedrock ; using MithrilShards.Example.Protocol ; using MithrilShards.Logging.Serilog ; using MithrilShards.Network.Bedrock ; using Serilog ; namespace MithrilShards.Example.Node { static class Program { static async Task Main ( string [] args ) { // Create a root command with some options var rootCommand = new RootCommand { new Option < string >( \"--settings\" , getDefaultValue : () => \"forge-settings.json\" , description : \"Specify the path to the forge settings file.\" ), new Option < string? >( \"--log-settings\" , getDefaultValue : () => null , description : \"Specify the path to the forge log settings file. If not specified, try to get logging information from the main forge settings file.\" ), new Option < int >( \"--protocol-version\" , getDefaultValue : () => KnownVersion . CurrentVersion , description : \"Specify the path to the forge settings file.\" ) }; rootCommand . Description = \"Example App\" ; rootCommand . TreatUnmatchedTokensAsErrors = false ; // Note that the parameters of the handler method are matched according to the names of the options rootCommand . Handler = CommandHandler . Create < string , string , int >( async ( settings , logSettings , protocolVersion ) => { await new ForgeBuilder () . UseForge < DefaultForge >( args , settings ) . UseSerilog ( logSettings ) . UseBedrockNetwork < ExampleNetworkProtocolMessageSerializer >() . UseStatisticsCollector ( options => options . DumpOnConsoleOnKeyPress = true ) /// we are injecting ExampleDev type to allow <see cref=\"MithrilShards.WebApi.WebApiShard\"/> to find all the controllers /// defined there because only controllers defined in an included shard assemblies are discovered automatically. /// Passing ExampleDev will cause dotnet runtime to load the assembly where ExampleDev Type is defined and every /// controllers defined there will be found later during <see cref=\"MithrilShards.WebApi.WebApiShard\"/> initialization. . UseApi ( options => options . ControllersSeeker = ( seeker ) => seeker . LoadAssemblyFromType < ExampleDev >()) . UseDevController () . UseExample ( KnownVersion . V1 , protocolVersion ) . RunConsoleAsync () . ConfigureAwait ( false ); }); await rootCommand . InvokeAsync ( args ). ConfigureAwait ( false ); } } }", "title": "MithrilShards.Example.Node"}, {"location": "example-projects/mithril-shards-example/", "text": "MithrilShards.Example project represents the core project where most of the fundamental example application classes lies. Most of the custom application code is implemented here: network classes like a custom IPeerContext implementation and its factory class some custom IServerPeerConnectionGuard implementation to filter incoming connections and a custom ConnectorBase implementation that contains the logic to connect to other peers protocol classes like INetworkMessage implementations of custom messages (payloads) and complex types used within their implementation. INetworkMessage and type serializators that serialize classes into a byte representation that can be sent through the network. INetworkMessage processors that contain the logic to parse incoming messages and send messages to other peers classes like shard class and its setting class that forms the plumbing of our application. custom services used by processors or other internal components like QuoteService . Main classes In the following sections we are going to dissect the project to expose and study the main classes implemented in the project. ExampleShard This class represents the core Example Shard, actually it doesn't contains any code but you could extend this example to start for example an async task when the shard starts ( StartAsync method) and stop it when it stops ( StopAsync method). Note that a shard StartAsync is implicitly called when the forge implementation starts, see [DefaultForge] for more information. ExampleSettings Holds configuration settings for the ExampleShard. You can declare everything may be useful to customize the behavior of the shard by configuration, in this simple example we have few properties 1 2 3 4 5 6 7 8 public class ExampleSettings : MithrilShardSettingsBase { const long DEFAULT_MAX_TIME_ADJUSTMENT = 70 * 60 ; public long MaxTimeAdjustment { get ; set ; } = DEFAULT_MAX_TIME_ADJUSTMENT ; public List < ExampleClientPeerBinding > Connections { get ; } = new List < ExampleClientPeerBinding >(); } Connections parameter is a list of ExampleClientPeerBinding instances that has been added to show how to define and use complex classes within a configuration settings class. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /// <summary> /// Client Peer endpoint the node would like to be connected to. /// </summary> public class ExampleClientPeerBinding { /// <summary>IP address and port number of the peer we wants to connect to.</summary> [IPEndPointValidator] [Required] public string? EndPoint { get ; set ; } public string? AdditionalInformation { get ; set ; } public bool TryGetExampleEndPoint ([ MaybeNullWhen ( false )] out ExampleEndPoint endPoint ) { endPoint = null ; if (! IPEndPoint . TryParse ( EndPoint ?? string . Empty , out IPEndPoint ? ipEndPoint )) { return false ; } if ( AdditionalInformation == null ) { return false ; } endPoint = new ExampleEndPoint ( ipEndPoint . Address , ipEndPoint . Port , AdditionalInformation ); return true ; } } Validating settings ExampleClientPeerBinding class has an EndPoint property that represents the endpoint (IP:Address) of a remote node we'd like to connect to and it's decorated with attributes that are used to validate the configuration during the initialization of the forge. Validation of the settings make use of System.ComponentModel.DataAnnotations and RequiredAttribute used in the example is one of those attribute that belongs to standard set. A different story is [IPEndPointValidator]: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /// <summary> /// Ensure the value is a valid IPEndPoint. /// Null value is considered valid, use <see cref=\"RequiredAttribute\"/> if you don't want to allow null values. /// </summary> /// <seealso cref=\"System.ComponentModel.DataAnnotations.ValidationAttribute\" /> [AttributeUsage(AttributeTargets.Field | AttributeTargets.Property, AllowMultiple = false, Inherited = true)] public class IPEndPointValidator : ValidationAttribute { protected override ValidationResult ? IsValid ( object? value , ValidationContext validationContext ) { if ( value is null ) return ValidationResult . Success ; string instance = value as string ?? string . Empty ; if (! IPEndPoint . TryParse ( instance , out IPEndPoint ? _ )) { return new ValidationResult ( $\"Not a valid EndPoint ({instance})\" , new string [] { validationContext . MemberName ! }); } return ValidationResult . Success ; } } This is a concrete example about how to perform validation for custom settings when default validation attributes aren't enough. Tip Validating settings is important because would stop the node during the forge build process if some settings aren't properly configured, for example if the settings file is malformed or instead of an expected endpoint like in this case, the user specify an incorrect endpoint string. Having a sanity check during validation, allows you to write simpler code when you make use of the setting file, because you can be assured that the values are correct. Configuration file To populate ExampleSettings file by using a json configuration file, we have to add Example section in your application configuration file 1 2 3 4 5 6 7 8 9 \"Example\" : { \"MaxTimeAdjustment\" : 4200 , \"Connections\" : [ { \"Endpoint\" : \"127.0.0.1:45061\" , \"AdditionalInformation\" : \"I'm cool!\" } ] } Important By inheriting a setting class from [MithrilShardSettingsBase], the section name to specify in the json file is the name of the setting class without the suffix \" Settings \". ExampleSettings becomes then Example. You can override this behavior by overriding ConfigurationSection property in your settings file. IQuoteService This interface (and its QuoteService implementation) is an example of a service used within the example application to provide a random quote to send as a message to our pong reply. It's definition is purposely simple: 1 2 3 4 5 6 public interface IQuoteService { List < string > Quotes { get ; } string GetRandomQuote (); } Warning In a proper application you wouldn't want to expose directly a list of quotes but rather expose methods like GetQuotes, AddQuote, RemoveQuote, anyway this example goal is to showcase Mithril Shards library and not to teach about how properly write your services classes. QuoteService implementation simply initialize a list of quotes (from The Lord of the Rings movies and books!), exposes the resulting list as a property that can be updated and a method GetRandomQuote to return a random quote from the available quotes. Tip As a further excercise you could try to implement a persistence layer for QuoteService, or a complete different implementation and then replace default QuoteService registration with your own! ServerPeerConnectionGuardBase This class implements the interface [IServerPeerConnectionGuard] whose purpose is to validate an incoming connection before we attempt to handshake and exchange information with it. It's an abstract class and its purpose is to implement generic useful code to be used by concrete peer guard implementations in such a way that guard implementation has just to focus on the guarding rule. Currently the example implements two guards: MaxConnectionThresholdGuard makes use of ForgeConnectivitySettings to ensure that the number of incoming transaction doesn't exceeds the MaxInboundConnections settings value. BannedPeerGuard ensures that the connecting node isn't flagged as banned in our IPeerAddressBook. Actually it's not honored because the default IPeerAddressBook implementation ( DefaultPeerAddressBook ) is a fake implementation that just log messages but does nothing. As a reference, this is the MaxConnectionThresholdGuard implementation: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class MaxConnectionThresholdGuard : ServerPeerConnectionGuardBase { readonly IConnectivityPeerStats _peerStats ; public MaxConnectionThresholdGuard ( ILogger < MaxConnectionThresholdGuard > logger , IOptions < ForgeConnectivitySettings > settings , IConnectivityPeerStats serverPeerStats ) : base ( logger , settings ) { _peerStats = serverPeerStats ; } internal override string? TryGetDenyReason ( IPeerContext peerContext ) { if ( _peerStats . ConnectedInboundPeersCount >= settings . MaxInboundConnections ) { return \"Inbound connection refused: max connection threshold reached.\" ; } return null ; } } ExampleRequiredConnection This class implements [IConnector], extending ConnectorBase abstract class. A RequiredConnection connector is already implemented and added by default when we build a forge, this example shows how you can override default registered services with a custom implementation: ExampleRequiredConnection is meant to replace RequiredConnection. By default, to instruct our node to try to connect to specific remote nodes, we can specify these endpoints in ForgeConnectivitySettings Connections property and the RequiredConnection connector will attempt to connect to the specified nodes automatically but since we have our custom list of remote endpoints defined in our ExampleSettings Connections property, we want to use that list instead. Info Check ReplaceServices method in ForgeBuilderExtensions.cs class to see how service replacement is performed. Protocol Messages Of course in a P2P example application we have to talk with other peers, so we need messages to exchange! In this example we implemented four messages: two for the handshake process (borrowed by bitcoin protocol), namely VerackMessage and VersionMessage and two to implement the ping pong logic: PingMessage and PongMessage . Let's just examine one of them and lets pick the one that contains a complex type that has to be serialized over the network. PongMessage 1 2 3 4 5 6 7 8 [NetworkMessage(COMMAND)] public sealed class PongMessage : INetworkMessage { private const string COMMAND = \"pong\" ; string INetworkMessage . Command => COMMAND ; public PongFancyResponse ? PongFancyResponse { get ; set ; } } A message has to implement [INetworkMessage] interface and be decorated with the [NetworkMessageAttribute] in order to be serialized by the [NetworkMessageSerializerManager]. Since the message name, exposed by the Command property, is used both as the return value of the property and as the parameter passed to the NetworkMessageAttribute, a private const string is used to prevent manual errors when creating a new message: just edit the message name in one place. The PongMessage payload just contains one serialized property, PongFancyResponse, and the PongMessageSerializer will show how to serialize this complex type. PongFancyResponse This type represent a complex type that is serialized when we send a PongMessage to a peer. We could have added the property that this type contains, straight into the PongMessage class but since this example project has the goal to showcase Mithril Shards features, having a complex type is useful to describe the process needed to handle such scenarios. The class itself is a simple POCO class (it's POCO by choice but it's not mandatory to be so, you can use any kind of class, as long as you implement a serializer for that specific type) 1 2 3 4 5 6 7 8 9 public class PongFancyResponse { /// <summary> /// The nonce received from the ping request. /// </summary> public ulong Nonce { get ; set ; } public string? Quote { get ; set ; } } Nonce is a simple unsigned long value that's used to link a pong response to a ping request, just returning back the ping Nonce value, while Quote is a nullable string that contains the Quote generated by the node sending the PongMessage. Note Projects within Mithril Shards solution make use of nullable references types and proper .editorconfig configuration to raise warning and exceptions in multiple scenarios and proudly have a 0 warning build (most of the time ). Protocol Messages Serializers Like for messages, their serializer has to implement an interface, in this case to follow DRY, a base generic class ExampleNetworkMessageSerializerBase<TMessage> is implemented that acts just as placeholder because it contains no code except an empty method and some comments, that explain how doing so you can expand a serializer by having a custom [IPeerContext] like in this example and some helper methods you may find useful in your implementation. Usually you have one message serializer for each message you have, so in this case we have four message serializers: VersionMessageSerializer, VerackMessageSerializer, PingMessageSerializer and PongMessageSerializer. PongMessageSerializer Since we have already described the PongMessage in details, makes sense to explain its serializer: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /// <summary> /// PongMessage serializer, used to serialize and send through the network a <see cref=\"PongMessage\"/> /// </summary> /// <seealso cref=\"ExampleNetworkMessageSerializerBase{PongMessage}\" /> public class PongMessageSerializer : ExampleNetworkMessageSerializerBase < PongMessage > { readonly IProtocolTypeSerializer < PongFancyResponse > _pongFancyResponseSerializator ; public PongMessageSerializer ( IProtocolTypeSerializer < PongFancyResponse > pongFancyResponseSerializator ) { /// since the pong message has a complex type that can be reused in other payload (well, /// this is specific to pong but you get the idea) we are implementing a custom /// type serializer and inject it into this message serializer _pongFancyResponseSerializator = pongFancyResponseSerializator ; } public override void Serialize ( PongMessage message , int protocolVersion , ExamplePeerContext peerContext , IBufferWriter < byte > output ) { output . WriteWithSerializer ( message . PongFancyResponse !, protocolVersion , _pongFancyResponseSerializator ); } public override PongMessage Deserialize ( ref SequenceReader < byte > reader , int protocolVersion , ExamplePeerContext peerContext ) { return new PongMessage { PongFancyResponse = reader . ReadWithSerializer ( protocolVersion , _pongFancyResponseSerializator ) }; } } What to highlight in this code is: PongMessageSerializer declares it's a serializer for the PongMessage by extending ExampleNetworkMessageSerializerBase<PongMessage> (note that the generic type argument is PongMessage) It's constructor accepts a IProtocolTypeSerializer<PongFancyResponse> pongFancyResponseSerializator , this will be injected automatically by the DI container when the serializer is resolved and it will be used to serialize the complex type PongFancyResponse. Later we'll see the PongFancyResponseSerializer that will be used, note how actually we ask for a IProtocolTypeSerializer and at runtime our serializer PongFancyResponseSerializer will be used, no need to worry about knowing the real implementation of our serializer, we can even change it at runtime or using a custom feature that changes serializers, that's the power of abstraction ! We have to implement Serialize and Deserialize methods and in this example we are just relying on the extension WriteWithSerializer and ReadWithSerializer , nothing easier than that. If we had other primitive types to serialize, like an integer property, we had just to use the proper IBufferWriter<byte> primitive extension WriteInt (to serialize) and SequenceReader<byte> ReadInt primitive extension (to read). Info You are encouraged to check source code: IBufferWriterExtensions.cs and SequenceReaderExtensions.cs classes contains all the primitive extensions to serialize primitive types and helper to leverage the use of IProtocolTypeSerializer used to serialize complex types. Protocol Types Serializers When a message contains a complex type like our PongFancyResponse type, we can make use of IProtocolTypeSerializer implementations. In our example we have the PongFancryResponseSerializer class that we can study 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class PongFancyResponseSerializer : IProtocolTypeSerializer < PongFancyResponse > { public int Serialize ( PongFancyResponse typeInstance , int protocolVersion , IBufferWriter < byte > writer , ProtocolTypeSerializerOptions ? options = null ) { int size = 0 ; size += writer . WriteULong ( typeInstance . Nonce ); size += writer . WriteVarString ( typeInstance . Quote ); return size ; } public PongFancyResponse Deserialize ( ref SequenceReader < byte > reader , int protocolVersion , ProtocolTypeSerializerOptions ? options = null ) { return new PongFancyResponse { Nonce = reader . ReadULong (), Quote = reader . ReadVarString () }; } } The logic is similar to message serializer, we have to implement the interface IProtocolTypeSerializer<TComplextype> that requires us to implement the Serialize and Deserialize method. In this specific example we can see how an unsigned long and a nullable string are serialized in our protocol implementaiton. Tip IProtocolTypeSerializer implementations can inject other IProtocolTypeSerializer implementations if they include other complex types. Processors Processors are fundamental classes that allow us to react to incoming messages. Mithril Shards has a clever way to handle messages: whenever a stream of data arrives, it gets read to see if it represents a known messages and if it's the case, all the processors that are registered as interested in that particular message are activated. Technically it's like a publish-subscribe pattern but it's transparent for the developer, everything it's handled by following conventions and implementing specific classes. Processors are attached to a peer context by the Mithril Shards core class NetworkMessageProcessorFactory, their lifetime scope is defined as Transient, this mean that each peer context has its own processor instance attached (processors aren't mean to natively share data between peers but you can anyway create a singleton service that inject in the processor to do so). In our example, an abstract BaseProcessor class implements the code to deal with common needs, it has a lot of helper methods that allow you to subscribe and unsubscribe to event bus messages, react to peer handshake, send messages, execute conditional statement asynchronously and much more (check out the BaseProcess.cs file). Processors can be quite complex, in this example PingPongProcessor is quite simple but still contains useful snippets that you can learn and use. PingPongProcessor To shed some light on this, let's inspect the PingPongProcessor, whose goal is to process incoming ping requests and reply with pong messages, or generate ping messages after a certain period of time that has elapsed (it's not meant to be an optimized protocol, in such case you'd want to ping only if you don't receive data from the peer for a certain time, but the goal is to keep the example simple in logic but exhaustive as implementation). Declaration This time I'm not including the full class source code but just meaningful snippets, let's start from the declaration: 1 2 3 public partial class PingPongProcessor : BaseProcessor , INetworkMessageHandler < PingMessage >, INetworkMessageHandler < PongMessage > PingPongProcessor inherits from BaseProcessor and is declared as a partial class, because its internal status is declared as an inner class and defined into a nested file PingProcessor.Status.cs. This allow us to restrict Status scope while keeping our source more compact. In visual studio the inner file is shown as a child of the PingProngProcessor.cs as you can see. It also implements two interfaces: INetworkMessageHandler<PingMessage> and INetworkMessageHandler<PongMessage> . Implementing INetworkMessageHandler generic interface is a way to instruct the Mithril Shards framework that this processor is interested in handling incoming PingMessage and PongMessage. Declarative syntax like this allow us to maintain better our code when we have several processors and allow us to have a better control over which process elaborates which messages without much effort. Constructor 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public PingPongProcessor ( ILogger < PingPongProcessor > logger , IEventBus eventBus , IPeerBehaviorManager peerBehaviorManager , IRandomNumberGenerator randomNumberGenerator , IDateTimeProvider dateTimeProvider , IPeriodicWork periodicPing , IQuoteService quoteService ) : base ( logger , eventBus , peerBehaviorManager , isHandshakeAware : true , receiveMessagesOnlyIfHandshaked : true ) { _randomNumberGenerator = randomNumberGenerator ; _dateTimeProvider = dateTimeProvider ; _periodicPing = periodicPing ; _quoteService = quoteService ; } The constructor declares which services we need and calls the base constructor passing its needed services. I'd emphasize the last 2 base constructor parameter that I've specified by using named arguments to better show their meaning: isHandshakeAware: true, receiveMessagesOnlyIfHandshaked: true Specifying true to isHandshakeAware means that the processor is handshake aware and when our peer handshake correctly with a remote peer, OnPeerHandshakedAsync method is invoked. In our example we uses this information to start a periodic task that ensures that we send a ping request every PING_INTERVAL amount of time 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 protected override ValueTask OnPeerHandshakedAsync () { _ = _periodicPing . StartAsync ( label : $\"{nameof(_periodicPing)}-{PeerContext.PeerId}\" , work : PingAsync , interval : TimeSpan . FromSeconds ( PING_INTERVAL ), cancellation : PeerContext . ConnectionCancellationTokenSource . Token ); return default ; } private async Task PingAsync ( CancellationToken cancellationToken ) { var ping = new PingMessage (); ping . Nonce = _randomNumberGenerator . GetUint64 (); await SendMessageAsync ( ping ). ConfigureAwait ( false ); _status . PingSent ( _dateTimeProvider . GetTimeMicros (), ping ); logger . LogDebug ( \"Sent ping request with nonce {PingNonce}\" , _status . PingRequestNonce ); //in case of memory leak, investigate this. _pingCancellationTokenSource = CancellationTokenSource . CreateLinkedTokenSource ( cancellationToken ); // ensures the handshake is performed timely await DisconnectIfAsync (() => { return new ValueTask < bool >( _status . PingResponseTime == 0 ); }, TimeSpan . FromSeconds ( TIMEOUT_INTERVAL ), \"Pong not received in time\" , _pingCancellationTokenSource . Token ). ConfigureAwait ( false ); } The call to DisconnectIfAsync within PingAsync method, ensures that if the other peers doesn't reply to us with a proper pong messages, we disconnect from the remote peer. The action passed to DisconnectIfAsync gets evaluated when the time specified by TimeSpan.FromSeconds(TIMEOUT_INTERVAL) elapses. Current status of our processor is held in the inner Status class, when we call its PingSent we are resetting the PingResponseTime to 0. When we receive a pong message PingResponseTime is set to a value and thus when the timeout elapses we are expected to find a value if the peer replied, or 0 if it didn't (and thus disconnect the peer). Warning This logic to works requires that TIMEOUT_INTERVAL is lower than PING_INTERVAL. Handling the PingMessage As we saw earlier, we declared that the class was implementing INetworkMessageHandler , this mean that we have to implement its ProcessMessageAsync where we can put our logic to handle the ping message: 1 2 3 4 5 6 7 8 9 10 11 12 13 async ValueTask < bool > INetworkMessageHandler < PingMessage >. ProcessMessageAsync ( PingMessage message , CancellationToken cancellation ) { await SendMessageAsync ( new PongMessage { PongFancyResponse = new PongFancyResponse { Nonce = message . Nonce , Quote = _quoteService . GetRandomQuote () } }). ConfigureAwait ( false ); return true ; } This method is pretty simple, it just sends an async PongMessage, returning the original ping Nonce and a random quote picked from the IQuoteService implementation. Note In this example, ProcessMessageAsync has been implemented as an explicit implementation of the interface , this allows us to hide these methods from the publicly available methods of the type. Handling the PongMessage Similarly to the PingMessage handler, we implements PongMessage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ValueTask < bool > INetworkMessageHandler < PongMessage >. ProcessMessageAsync ( PongMessage message , CancellationToken cancellation ) { if ( _status . PingRequestNonce != 0 && message . PongFancyResponse ?. Nonce == _status . PingRequestNonce ) { ( ulong Nonce , long RoundTrip ) = _status . PongReceived ( _dateTimeProvider . GetTimeMicros ()); logger . LogDebug ( \"Received pong with nonce {PingNonce} in {PingRoundTrip} usec. {Quote}\" , Nonce , RoundTrip , message . PongFancyResponse . Quote ); _pingCancellationTokenSource . Cancel (); } else { logger . LogDebug ( \"Received pong with wrong nonce: {PingNonce}\" , _status . PingRequestNonce ); } return new ValueTask < bool >( true ); } In this method we check that the returned Nonce is the same of our last ping request, if so we update our internal status to signal that we received the pong message. Add the shard into the forge To add the shard to the forge, the [IForgeBuilder] extension UseExample in ForgeBuilderExtensions class has to be used, here what it does: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 /// <summary> /// Inject the Example shard. /// </summary> /// <param name=\"forgeBuilder\">The forge builder.</param> /// <param name=\"minimumSupportedVersion\">The minimum version local nodes requires in order to connect to other peers.</param> /// <param name=\"currentVersion\">The current version local peer aim to use with connected peers.</param> /// <returns></returns> public static IForgeBuilder UseExample ( this IForgeBuilder forgeBuilder , int minimumSupportedVersion , int currentVersion ) { if ( forgeBuilder is null ) throw new ArgumentNullException ( nameof ( forgeBuilder )); forgeBuilder . AddShard < ExampleShard , ExampleSettings >( ( hostBuildContext , services ) => { services . AddSingleton ( new NodeImplementation ( minimumSupportedVersion , currentVersion )) . AddSingleton < IDateTimeProvider , DateTimeProvider >() . AddSingleton < IQuoteService , QuoteService >() . AddPeerGuards () . AddMessageSerializers () . AddProtocolTypeSerializers () . AddMessageProcessors () . ReplaceServices (); }); return forgeBuilder ; } As you can see it makes use of AddShard method to register the ExampleShard and specify its settings ( ExampleSettings ). AddShards exposes an action where you can leverage to register custom services, like in this case IDateTimeProvider, IQuoteService and a lot more. This is a very important aspect because allows you Tip While it's possible to add all service within the AddShard action parameter, I encourage you to split registrations based on their scope and responsibility, like in the example above, it allows you to have a better code base that's easier to manage. You can check the ForgeBuilderExtensions.cs file in MithrilShards.Example project to see all services registered, for example AddPeerGuards is a method in the same file that adds some [IServerPeerConnectionGuard]). AddMessageSerializers and AddProtocolTypeSerializers are two interesting methods that use reflection to automatically register all [INetworkMessageSerializer] and [IProtocolTypeSerializer] defined in this class without having to manually register each one.", "title": "MithrilShards.Example"}, {"location": "example-projects/mithril-shards-example/#main-classes", "text": "In the following sections we are going to dissect the project to expose and study the main classes implemented in the project.", "title": "Main classes"}, {"location": "example-projects/mithril-shards-example/#exampleshard", "text": "This class represents the core Example Shard, actually it doesn't contains any code but you could extend this example to start for example an async task when the shard starts ( StartAsync method) and stop it when it stops ( StopAsync method). Note that a shard StartAsync is implicitly called when the forge implementation starts, see [DefaultForge] for more information.", "title": "ExampleShard"}, {"location": "example-projects/mithril-shards-example/#examplesettings", "text": "Holds configuration settings for the ExampleShard. You can declare everything may be useful to customize the behavior of the shard by configuration, in this simple example we have few properties 1 2 3 4 5 6 7 8 public class ExampleSettings : MithrilShardSettingsBase { const long DEFAULT_MAX_TIME_ADJUSTMENT = 70 * 60 ; public long MaxTimeAdjustment { get ; set ; } = DEFAULT_MAX_TIME_ADJUSTMENT ; public List < ExampleClientPeerBinding > Connections { get ; } = new List < ExampleClientPeerBinding >(); } Connections parameter is a list of ExampleClientPeerBinding instances that has been added to show how to define and use complex classes within a configuration settings class. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /// <summary> /// Client Peer endpoint the node would like to be connected to. /// </summary> public class ExampleClientPeerBinding { /// <summary>IP address and port number of the peer we wants to connect to.</summary> [IPEndPointValidator] [Required] public string? EndPoint { get ; set ; } public string? AdditionalInformation { get ; set ; } public bool TryGetExampleEndPoint ([ MaybeNullWhen ( false )] out ExampleEndPoint endPoint ) { endPoint = null ; if (! IPEndPoint . TryParse ( EndPoint ?? string . Empty , out IPEndPoint ? ipEndPoint )) { return false ; } if ( AdditionalInformation == null ) { return false ; } endPoint = new ExampleEndPoint ( ipEndPoint . Address , ipEndPoint . Port , AdditionalInformation ); return true ; } }", "title": "ExampleSettings"}, {"location": "example-projects/mithril-shards-example/#validating-settings", "text": "ExampleClientPeerBinding class has an EndPoint property that represents the endpoint (IP:Address) of a remote node we'd like to connect to and it's decorated with attributes that are used to validate the configuration during the initialization of the forge. Validation of the settings make use of System.ComponentModel.DataAnnotations and RequiredAttribute used in the example is one of those attribute that belongs to standard set. A different story is [IPEndPointValidator]: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /// <summary> /// Ensure the value is a valid IPEndPoint. /// Null value is considered valid, use <see cref=\"RequiredAttribute\"/> if you don't want to allow null values. /// </summary> /// <seealso cref=\"System.ComponentModel.DataAnnotations.ValidationAttribute\" /> [AttributeUsage(AttributeTargets.Field | AttributeTargets.Property, AllowMultiple = false, Inherited = true)] public class IPEndPointValidator : ValidationAttribute { protected override ValidationResult ? IsValid ( object? value , ValidationContext validationContext ) { if ( value is null ) return ValidationResult . Success ; string instance = value as string ?? string . Empty ; if (! IPEndPoint . TryParse ( instance , out IPEndPoint ? _ )) { return new ValidationResult ( $\"Not a valid EndPoint ({instance})\" , new string [] { validationContext . MemberName ! }); } return ValidationResult . Success ; } } This is a concrete example about how to perform validation for custom settings when default validation attributes aren't enough. Tip Validating settings is important because would stop the node during the forge build process if some settings aren't properly configured, for example if the settings file is malformed or instead of an expected endpoint like in this case, the user specify an incorrect endpoint string. Having a sanity check during validation, allows you to write simpler code when you make use of the setting file, because you can be assured that the values are correct.", "title": "Validating settings"}, {"location": "example-projects/mithril-shards-example/#configuration-file", "text": "To populate ExampleSettings file by using a json configuration file, we have to add Example section in your application configuration file 1 2 3 4 5 6 7 8 9 \"Example\" : { \"MaxTimeAdjustment\" : 4200 , \"Connections\" : [ { \"Endpoint\" : \"127.0.0.1:45061\" , \"AdditionalInformation\" : \"I'm cool!\" } ] } Important By inheriting a setting class from [MithrilShardSettingsBase], the section name to specify in the json file is the name of the setting class without the suffix \" Settings \". ExampleSettings becomes then Example. You can override this behavior by overriding ConfigurationSection property in your settings file.", "title": "Configuration file"}, {"location": "example-projects/mithril-shards-example/#iquoteservice", "text": "This interface (and its QuoteService implementation) is an example of a service used within the example application to provide a random quote to send as a message to our pong reply. It's definition is purposely simple: 1 2 3 4 5 6 public interface IQuoteService { List < string > Quotes { get ; } string GetRandomQuote (); } Warning In a proper application you wouldn't want to expose directly a list of quotes but rather expose methods like GetQuotes, AddQuote, RemoveQuote, anyway this example goal is to showcase Mithril Shards library and not to teach about how properly write your services classes. QuoteService implementation simply initialize a list of quotes (from The Lord of the Rings movies and books!), exposes the resulting list as a property that can be updated and a method GetRandomQuote to return a random quote from the available quotes. Tip As a further excercise you could try to implement a persistence layer for QuoteService, or a complete different implementation and then replace default QuoteService registration with your own!", "title": "IQuoteService"}, {"location": "example-projects/mithril-shards-example/#serverpeerconnectionguardbase", "text": "This class implements the interface [IServerPeerConnectionGuard] whose purpose is to validate an incoming connection before we attempt to handshake and exchange information with it. It's an abstract class and its purpose is to implement generic useful code to be used by concrete peer guard implementations in such a way that guard implementation has just to focus on the guarding rule. Currently the example implements two guards: MaxConnectionThresholdGuard makes use of ForgeConnectivitySettings to ensure that the number of incoming transaction doesn't exceeds the MaxInboundConnections settings value. BannedPeerGuard ensures that the connecting node isn't flagged as banned in our IPeerAddressBook. Actually it's not honored because the default IPeerAddressBook implementation ( DefaultPeerAddressBook ) is a fake implementation that just log messages but does nothing. As a reference, this is the MaxConnectionThresholdGuard implementation: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class MaxConnectionThresholdGuard : ServerPeerConnectionGuardBase { readonly IConnectivityPeerStats _peerStats ; public MaxConnectionThresholdGuard ( ILogger < MaxConnectionThresholdGuard > logger , IOptions < ForgeConnectivitySettings > settings , IConnectivityPeerStats serverPeerStats ) : base ( logger , settings ) { _peerStats = serverPeerStats ; } internal override string? TryGetDenyReason ( IPeerContext peerContext ) { if ( _peerStats . ConnectedInboundPeersCount >= settings . MaxInboundConnections ) { return \"Inbound connection refused: max connection threshold reached.\" ; } return null ; } }", "title": "ServerPeerConnectionGuardBase"}, {"location": "example-projects/mithril-shards-example/#examplerequiredconnection", "text": "This class implements [IConnector], extending ConnectorBase abstract class. A RequiredConnection connector is already implemented and added by default when we build a forge, this example shows how you can override default registered services with a custom implementation: ExampleRequiredConnection is meant to replace RequiredConnection. By default, to instruct our node to try to connect to specific remote nodes, we can specify these endpoints in ForgeConnectivitySettings Connections property and the RequiredConnection connector will attempt to connect to the specified nodes automatically but since we have our custom list of remote endpoints defined in our ExampleSettings Connections property, we want to use that list instead. Info Check ReplaceServices method in ForgeBuilderExtensions.cs class to see how service replacement is performed.", "title": "ExampleRequiredConnection"}, {"location": "example-projects/mithril-shards-example/#protocol-messages", "text": "Of course in a P2P example application we have to talk with other peers, so we need messages to exchange! In this example we implemented four messages: two for the handshake process (borrowed by bitcoin protocol), namely VerackMessage and VersionMessage and two to implement the ping pong logic: PingMessage and PongMessage . Let's just examine one of them and lets pick the one that contains a complex type that has to be serialized over the network.", "title": "Protocol Messages"}, {"location": "example-projects/mithril-shards-example/#pongmessage", "text": "1 2 3 4 5 6 7 8 [NetworkMessage(COMMAND)] public sealed class PongMessage : INetworkMessage { private const string COMMAND = \"pong\" ; string INetworkMessage . Command => COMMAND ; public PongFancyResponse ? PongFancyResponse { get ; set ; } } A message has to implement [INetworkMessage] interface and be decorated with the [NetworkMessageAttribute] in order to be serialized by the [NetworkMessageSerializerManager]. Since the message name, exposed by the Command property, is used both as the return value of the property and as the parameter passed to the NetworkMessageAttribute, a private const string is used to prevent manual errors when creating a new message: just edit the message name in one place. The PongMessage payload just contains one serialized property, PongFancyResponse, and the PongMessageSerializer will show how to serialize this complex type.", "title": "PongMessage"}, {"location": "example-projects/mithril-shards-example/#pongfancyresponse", "text": "This type represent a complex type that is serialized when we send a PongMessage to a peer. We could have added the property that this type contains, straight into the PongMessage class but since this example project has the goal to showcase Mithril Shards features, having a complex type is useful to describe the process needed to handle such scenarios. The class itself is a simple POCO class (it's POCO by choice but it's not mandatory to be so, you can use any kind of class, as long as you implement a serializer for that specific type) 1 2 3 4 5 6 7 8 9 public class PongFancyResponse { /// <summary> /// The nonce received from the ping request. /// </summary> public ulong Nonce { get ; set ; } public string? Quote { get ; set ; } } Nonce is a simple unsigned long value that's used to link a pong response to a ping request, just returning back the ping Nonce value, while Quote is a nullable string that contains the Quote generated by the node sending the PongMessage. Note Projects within Mithril Shards solution make use of nullable references types and proper .editorconfig configuration to raise warning and exceptions in multiple scenarios and proudly have a 0 warning build (most of the time ).", "title": "PongFancyResponse"}, {"location": "example-projects/mithril-shards-example/#protocol-messages-serializers", "text": "Like for messages, their serializer has to implement an interface, in this case to follow DRY, a base generic class ExampleNetworkMessageSerializerBase<TMessage> is implemented that acts just as placeholder because it contains no code except an empty method and some comments, that explain how doing so you can expand a serializer by having a custom [IPeerContext] like in this example and some helper methods you may find useful in your implementation. Usually you have one message serializer for each message you have, so in this case we have four message serializers: VersionMessageSerializer, VerackMessageSerializer, PingMessageSerializer and PongMessageSerializer.", "title": "Protocol Messages Serializers"}, {"location": "example-projects/mithril-shards-example/#pongmessageserializer", "text": "Since we have already described the PongMessage in details, makes sense to explain its serializer: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /// <summary> /// PongMessage serializer, used to serialize and send through the network a <see cref=\"PongMessage\"/> /// </summary> /// <seealso cref=\"ExampleNetworkMessageSerializerBase{PongMessage}\" /> public class PongMessageSerializer : ExampleNetworkMessageSerializerBase < PongMessage > { readonly IProtocolTypeSerializer < PongFancyResponse > _pongFancyResponseSerializator ; public PongMessageSerializer ( IProtocolTypeSerializer < PongFancyResponse > pongFancyResponseSerializator ) { /// since the pong message has a complex type that can be reused in other payload (well, /// this is specific to pong but you get the idea) we are implementing a custom /// type serializer and inject it into this message serializer _pongFancyResponseSerializator = pongFancyResponseSerializator ; } public override void Serialize ( PongMessage message , int protocolVersion , ExamplePeerContext peerContext , IBufferWriter < byte > output ) { output . WriteWithSerializer ( message . PongFancyResponse !, protocolVersion , _pongFancyResponseSerializator ); } public override PongMessage Deserialize ( ref SequenceReader < byte > reader , int protocolVersion , ExamplePeerContext peerContext ) { return new PongMessage { PongFancyResponse = reader . ReadWithSerializer ( protocolVersion , _pongFancyResponseSerializator ) }; } } What to highlight in this code is: PongMessageSerializer declares it's a serializer for the PongMessage by extending ExampleNetworkMessageSerializerBase<PongMessage> (note that the generic type argument is PongMessage) It's constructor accepts a IProtocolTypeSerializer<PongFancyResponse> pongFancyResponseSerializator , this will be injected automatically by the DI container when the serializer is resolved and it will be used to serialize the complex type PongFancyResponse. Later we'll see the PongFancyResponseSerializer that will be used, note how actually we ask for a IProtocolTypeSerializer and at runtime our serializer PongFancyResponseSerializer will be used, no need to worry about knowing the real implementation of our serializer, we can even change it at runtime or using a custom feature that changes serializers, that's the power of abstraction ! We have to implement Serialize and Deserialize methods and in this example we are just relying on the extension WriteWithSerializer and ReadWithSerializer , nothing easier than that. If we had other primitive types to serialize, like an integer property, we had just to use the proper IBufferWriter<byte> primitive extension WriteInt (to serialize) and SequenceReader<byte> ReadInt primitive extension (to read). Info You are encouraged to check source code: IBufferWriterExtensions.cs and SequenceReaderExtensions.cs classes contains all the primitive extensions to serialize primitive types and helper to leverage the use of IProtocolTypeSerializer used to serialize complex types.", "title": "PongMessageSerializer"}, {"location": "example-projects/mithril-shards-example/#protocol-types-serializers", "text": "When a message contains a complex type like our PongFancyResponse type, we can make use of IProtocolTypeSerializer implementations. In our example we have the PongFancryResponseSerializer class that we can study 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class PongFancyResponseSerializer : IProtocolTypeSerializer < PongFancyResponse > { public int Serialize ( PongFancyResponse typeInstance , int protocolVersion , IBufferWriter < byte > writer , ProtocolTypeSerializerOptions ? options = null ) { int size = 0 ; size += writer . WriteULong ( typeInstance . Nonce ); size += writer . WriteVarString ( typeInstance . Quote ); return size ; } public PongFancyResponse Deserialize ( ref SequenceReader < byte > reader , int protocolVersion , ProtocolTypeSerializerOptions ? options = null ) { return new PongFancyResponse { Nonce = reader . ReadULong (), Quote = reader . ReadVarString () }; } } The logic is similar to message serializer, we have to implement the interface IProtocolTypeSerializer<TComplextype> that requires us to implement the Serialize and Deserialize method. In this specific example we can see how an unsigned long and a nullable string are serialized in our protocol implementaiton. Tip IProtocolTypeSerializer implementations can inject other IProtocolTypeSerializer implementations if they include other complex types.", "title": "Protocol Types Serializers"}, {"location": "example-projects/mithril-shards-example/#processors", "text": "Processors are fundamental classes that allow us to react to incoming messages. Mithril Shards has a clever way to handle messages: whenever a stream of data arrives, it gets read to see if it represents a known messages and if it's the case, all the processors that are registered as interested in that particular message are activated. Technically it's like a publish-subscribe pattern but it's transparent for the developer, everything it's handled by following conventions and implementing specific classes. Processors are attached to a peer context by the Mithril Shards core class NetworkMessageProcessorFactory, their lifetime scope is defined as Transient, this mean that each peer context has its own processor instance attached (processors aren't mean to natively share data between peers but you can anyway create a singleton service that inject in the processor to do so). In our example, an abstract BaseProcessor class implements the code to deal with common needs, it has a lot of helper methods that allow you to subscribe and unsubscribe to event bus messages, react to peer handshake, send messages, execute conditional statement asynchronously and much more (check out the BaseProcess.cs file). Processors can be quite complex, in this example PingPongProcessor is quite simple but still contains useful snippets that you can learn and use.", "title": "Processors"}, {"location": "example-projects/mithril-shards-example/#pingpongprocessor", "text": "To shed some light on this, let's inspect the PingPongProcessor, whose goal is to process incoming ping requests and reply with pong messages, or generate ping messages after a certain period of time that has elapsed (it's not meant to be an optimized protocol, in such case you'd want to ping only if you don't receive data from the peer for a certain time, but the goal is to keep the example simple in logic but exhaustive as implementation).", "title": "PingPongProcessor"}, {"location": "example-projects/mithril-shards-example/#declaration", "text": "This time I'm not including the full class source code but just meaningful snippets, let's start from the declaration: 1 2 3 public partial class PingPongProcessor : BaseProcessor , INetworkMessageHandler < PingMessage >, INetworkMessageHandler < PongMessage > PingPongProcessor inherits from BaseProcessor and is declared as a partial class, because its internal status is declared as an inner class and defined into a nested file PingProcessor.Status.cs. This allow us to restrict Status scope while keeping our source more compact. In visual studio the inner file is shown as a child of the PingProngProcessor.cs as you can see. It also implements two interfaces: INetworkMessageHandler<PingMessage> and INetworkMessageHandler<PongMessage> . Implementing INetworkMessageHandler generic interface is a way to instruct the Mithril Shards framework that this processor is interested in handling incoming PingMessage and PongMessage. Declarative syntax like this allow us to maintain better our code when we have several processors and allow us to have a better control over which process elaborates which messages without much effort.", "title": "Declaration"}, {"location": "example-projects/mithril-shards-example/#constructor", "text": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 public PingPongProcessor ( ILogger < PingPongProcessor > logger , IEventBus eventBus , IPeerBehaviorManager peerBehaviorManager , IRandomNumberGenerator randomNumberGenerator , IDateTimeProvider dateTimeProvider , IPeriodicWork periodicPing , IQuoteService quoteService ) : base ( logger , eventBus , peerBehaviorManager , isHandshakeAware : true , receiveMessagesOnlyIfHandshaked : true ) { _randomNumberGenerator = randomNumberGenerator ; _dateTimeProvider = dateTimeProvider ; _periodicPing = periodicPing ; _quoteService = quoteService ; } The constructor declares which services we need and calls the base constructor passing its needed services. I'd emphasize the last 2 base constructor parameter that I've specified by using named arguments to better show their meaning: isHandshakeAware: true, receiveMessagesOnlyIfHandshaked: true Specifying true to isHandshakeAware means that the processor is handshake aware and when our peer handshake correctly with a remote peer, OnPeerHandshakedAsync method is invoked. In our example we uses this information to start a periodic task that ensures that we send a ping request every PING_INTERVAL amount of time 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 protected override ValueTask OnPeerHandshakedAsync () { _ = _periodicPing . StartAsync ( label : $\"{nameof(_periodicPing)}-{PeerContext.PeerId}\" , work : PingAsync , interval : TimeSpan . FromSeconds ( PING_INTERVAL ), cancellation : PeerContext . ConnectionCancellationTokenSource . Token ); return default ; } private async Task PingAsync ( CancellationToken cancellationToken ) { var ping = new PingMessage (); ping . Nonce = _randomNumberGenerator . GetUint64 (); await SendMessageAsync ( ping ). ConfigureAwait ( false ); _status . PingSent ( _dateTimeProvider . GetTimeMicros (), ping ); logger . LogDebug ( \"Sent ping request with nonce {PingNonce}\" , _status . PingRequestNonce ); //in case of memory leak, investigate this. _pingCancellationTokenSource = CancellationTokenSource . CreateLinkedTokenSource ( cancellationToken ); // ensures the handshake is performed timely await DisconnectIfAsync (() => { return new ValueTask < bool >( _status . PingResponseTime == 0 ); }, TimeSpan . FromSeconds ( TIMEOUT_INTERVAL ), \"Pong not received in time\" , _pingCancellationTokenSource . Token ). ConfigureAwait ( false ); } The call to DisconnectIfAsync within PingAsync method, ensures that if the other peers doesn't reply to us with a proper pong messages, we disconnect from the remote peer. The action passed to DisconnectIfAsync gets evaluated when the time specified by TimeSpan.FromSeconds(TIMEOUT_INTERVAL) elapses. Current status of our processor is held in the inner Status class, when we call its PingSent we are resetting the PingResponseTime to 0. When we receive a pong message PingResponseTime is set to a value and thus when the timeout elapses we are expected to find a value if the peer replied, or 0 if it didn't (and thus disconnect the peer). Warning This logic to works requires that TIMEOUT_INTERVAL is lower than PING_INTERVAL.", "title": "Constructor"}, {"location": "example-projects/mithril-shards-example/#handling-the-pingmessage", "text": "As we saw earlier, we declared that the class was implementing INetworkMessageHandler , this mean that we have to implement its ProcessMessageAsync where we can put our logic to handle the ping message: 1 2 3 4 5 6 7 8 9 10 11 12 13 async ValueTask < bool > INetworkMessageHandler < PingMessage >. ProcessMessageAsync ( PingMessage message , CancellationToken cancellation ) { await SendMessageAsync ( new PongMessage { PongFancyResponse = new PongFancyResponse { Nonce = message . Nonce , Quote = _quoteService . GetRandomQuote () } }). ConfigureAwait ( false ); return true ; } This method is pretty simple, it just sends an async PongMessage, returning the original ping Nonce and a random quote picked from the IQuoteService implementation. Note In this example, ProcessMessageAsync has been implemented as an explicit implementation of the interface , this allows us to hide these methods from the publicly available methods of the type.", "title": "Handling the PingMessage"}, {"location": "example-projects/mithril-shards-example/#handling-the-pongmessage", "text": "Similarly to the PingMessage handler, we implements PongMessage: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ValueTask < bool > INetworkMessageHandler < PongMessage >. ProcessMessageAsync ( PongMessage message , CancellationToken cancellation ) { if ( _status . PingRequestNonce != 0 && message . PongFancyResponse ?. Nonce == _status . PingRequestNonce ) { ( ulong Nonce , long RoundTrip ) = _status . PongReceived ( _dateTimeProvider . GetTimeMicros ()); logger . LogDebug ( \"Received pong with nonce {PingNonce} in {PingRoundTrip} usec. {Quote}\" , Nonce , RoundTrip , message . PongFancyResponse . Quote ); _pingCancellationTokenSource . Cancel (); } else { logger . LogDebug ( \"Received pong with wrong nonce: {PingNonce}\" , _status . PingRequestNonce ); } return new ValueTask < bool >( true ); } In this method we check that the returned Nonce is the same of our last ping request, if so we update our internal status to signal that we received the pong message.", "title": "Handling the PongMessage"}, {"location": "example-projects/mithril-shards-example/#add-the-shard-into-the-forge", "text": "To add the shard to the forge, the [IForgeBuilder] extension UseExample in ForgeBuilderExtensions class has to be used, here what it does: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 /// <summary> /// Inject the Example shard. /// </summary> /// <param name=\"forgeBuilder\">The forge builder.</param> /// <param name=\"minimumSupportedVersion\">The minimum version local nodes requires in order to connect to other peers.</param> /// <param name=\"currentVersion\">The current version local peer aim to use with connected peers.</param> /// <returns></returns> public static IForgeBuilder UseExample ( this IForgeBuilder forgeBuilder , int minimumSupportedVersion , int currentVersion ) { if ( forgeBuilder is null ) throw new ArgumentNullException ( nameof ( forgeBuilder )); forgeBuilder . AddShard < ExampleShard , ExampleSettings >( ( hostBuildContext , services ) => { services . AddSingleton ( new NodeImplementation ( minimumSupportedVersion , currentVersion )) . AddSingleton < IDateTimeProvider , DateTimeProvider >() . AddSingleton < IQuoteService , QuoteService >() . AddPeerGuards () . AddMessageSerializers () . AddProtocolTypeSerializers () . AddMessageProcessors () . ReplaceServices (); }); return forgeBuilder ; } As you can see it makes use of AddShard method to register the ExampleShard and specify its settings ( ExampleSettings ). AddShards exposes an action where you can leverage to register custom services, like in this case IDateTimeProvider, IQuoteService and a lot more. This is a very important aspect because allows you Tip While it's possible to add all service within the AddShard action parameter, I encourage you to split registrations based on their scope and responsibility, like in the example above, it allows you to have a better code base that's easier to manage. You can check the ForgeBuilderExtensions.cs file in MithrilShards.Example project to see all services registered, for example AddPeerGuards is a method in the same file that adds some [IServerPeerConnectionGuard]). AddMessageSerializers and AddProtocolTypeSerializers are two interesting methods that use reflection to automatically register all [INetworkMessageSerializer] and [IProtocolTypeSerializer] defined in this class without having to manually register each one.", "title": "Add the shard into the forge"}, {"location": "example-projects/running-example/", "text": "Running the example Running just an instance doesn't fully show you how the program behave, it needs at least 2 peers to connect to each other, that's why there are already multiple configuration files configured differently to let you connect two instances together. You can run one instance by setting MithrilShards.Example.Node as the startup project and run the launchSettings profile \"node1\" . Then open a shell at the MithrilShards.Example.Node project path and run the command below 1 dotnet run --no-build --settings forge-settings2.json This would cause you to have a debuggable instance running with the configuration defined in forge-settings.json file and another run running on the forge-settings2.json configuration. Alternatively you can run both instances, without a debugger (but you can attach later the process to Visual Studio) by running on two different shells: 1 2 dotnet run --no-build --settings forge-settings.json dotnet run --no-build --settings forge-settings2.json The program running forge-settings.json contains the most verbose log level and you'll have the best experience if you install (or use a docker image) of Seq configured on the port specified in your configuration file (e.g. localhost:5341). See [SerilogShard] for more details. Here an example of the configuration file (forge-settings.json) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 { \"ForgeConnectivity\" : { \"ForceShutdownAfter\" : 300 , \"MaxInboundConnections\" : 25 , \"AllowLoopbackConnection\" : false , \"Listeners\" : [ { \"IsWhitelistingEndpoint\" : true , \"Endpoint\" : \"0.0.0.0:45051\" }, { \"IsWhitelistingEndpoint\" : true , \"Endpoint\" : \"127.0.0.1:45052\" , \"PublicEndpoint\" : \"98.0.0.1:45011\" } ] }, \"Example\" : { \"MaxTimeAdjustment\" : 4200 , \"Connections\" : [ { \"Endpoint\" : \"127.0.0.1:45061\" , \"AdditionalInformation\" : \"I'm cool!\" } ] }, \"StatisticsCollector\" : { \"ContinuousConsoleDisplay\" : false , \"ContinuousConsoleDisplayRate\" : 5 }, \"DevController\" : { \"Enabled\" : true }, \"WebApi\" : { \"EndPoint\" : \"127.0.0.1:45020\" , \"Enabled\" : true , \"Https\" : false }, \"Serilog\" : { \"Using\" : [ \"Serilog.Sinks.Console\" , \"Serilog.Sinks.Seq\" ], \"Enrich\" : [ \"FromLogContext\" , \"WithMachineName\" , \"WithThreadId\" ], \"WriteTo\" : [ { \"Name\" : \"Console\" , \"Args\" : { \"IncludeScopes\" : true , \"theme\" : \"Serilog.Sinks.SystemConsole.Themes.AnsiConsoleTheme::Code, Serilog.Sinks.Console\" } }, { \"Name\" : \"Seq\" , \"Args\" : { \"serverUrl\" : \"http://localhost:5341\" } } ], \"MinimumLevel\" : { \"Default\" : \"Debug\" , \"Override\" : { \"Bedrock.Framework\" : \"Warning\" , \"Microsoft\" : \"Warning\" , \"System\" : \"Warning\" } } } } Some Screenshots Here a screenshot that shows the content of the shell when running the node with settings = forge-settings.json You can access the Swagger UI by opening the address https://127.0.0.1:45020/docs/index.html Here you can manipulate quotes using the Web API , or even manually attempt to connect to other peers using PeerManagement Connect action in the DEV area. If you installed Seq, you can access the logs in a better way like shown here:", "title": "Running the example"}, {"location": "example-projects/running-example/#running-the-example", "text": "Running just an instance doesn't fully show you how the program behave, it needs at least 2 peers to connect to each other, that's why there are already multiple configuration files configured differently to let you connect two instances together. You can run one instance by setting MithrilShards.Example.Node as the startup project and run the launchSettings profile \"node1\" . Then open a shell at the MithrilShards.Example.Node project path and run the command below 1 dotnet run --no-build --settings forge-settings2.json This would cause you to have a debuggable instance running with the configuration defined in forge-settings.json file and another run running on the forge-settings2.json configuration. Alternatively you can run both instances, without a debugger (but you can attach later the process to Visual Studio) by running on two different shells: 1 2 dotnet run --no-build --settings forge-settings.json dotnet run --no-build --settings forge-settings2.json The program running forge-settings.json contains the most verbose log level and you'll have the best experience if you install (or use a docker image) of Seq configured on the port specified in your configuration file (e.g. localhost:5341). See [SerilogShard] for more details. Here an example of the configuration file (forge-settings.json) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 { \"ForgeConnectivity\" : { \"ForceShutdownAfter\" : 300 , \"MaxInboundConnections\" : 25 , \"AllowLoopbackConnection\" : false , \"Listeners\" : [ { \"IsWhitelistingEndpoint\" : true , \"Endpoint\" : \"0.0.0.0:45051\" }, { \"IsWhitelistingEndpoint\" : true , \"Endpoint\" : \"127.0.0.1:45052\" , \"PublicEndpoint\" : \"98.0.0.1:45011\" } ] }, \"Example\" : { \"MaxTimeAdjustment\" : 4200 , \"Connections\" : [ { \"Endpoint\" : \"127.0.0.1:45061\" , \"AdditionalInformation\" : \"I'm cool!\" } ] }, \"StatisticsCollector\" : { \"ContinuousConsoleDisplay\" : false , \"ContinuousConsoleDisplayRate\" : 5 }, \"DevController\" : { \"Enabled\" : true }, \"WebApi\" : { \"EndPoint\" : \"127.0.0.1:45020\" , \"Enabled\" : true , \"Https\" : false }, \"Serilog\" : { \"Using\" : [ \"Serilog.Sinks.Console\" , \"Serilog.Sinks.Seq\" ], \"Enrich\" : [ \"FromLogContext\" , \"WithMachineName\" , \"WithThreadId\" ], \"WriteTo\" : [ { \"Name\" : \"Console\" , \"Args\" : { \"IncludeScopes\" : true , \"theme\" : \"Serilog.Sinks.SystemConsole.Themes.AnsiConsoleTheme::Code, Serilog.Sinks.Console\" } }, { \"Name\" : \"Seq\" , \"Args\" : { \"serverUrl\" : \"http://localhost:5341\" } } ], \"MinimumLevel\" : { \"Default\" : \"Debug\" , \"Override\" : { \"Bedrock.Framework\" : \"Warning\" , \"Microsoft\" : \"Warning\" , \"System\" : \"Warning\" } } } }", "title": "Running the example"}, {"location": "example-projects/running-example/#some-screenshots", "text": "Here a screenshot that shows the content of the shell when running the node with settings = forge-settings.json You can access the Swagger UI by opening the address https://127.0.0.1:45020/docs/index.html Here you can manipulate quotes using the Web API , or even manually attempt to connect to other peers using PeerManagement Connect action in the DEV area. If you installed Seq, you can access the logs in a better way like shown here:", "title": "Some Screenshots"}, {"location": "extension/", "text": "Extension The Blockcore Extension is an web browser add-on that can be installed to give you an easy to use wallet. Extension can be built and distributed in multiple instances, making it possible to easily adopt the extension for different blockchains, ecosystems and purposes. Blockcore Extension This is the primary instance that has all features that exists. It's used for development, testing and verification of functionality. CoinVault CoinVault is built for Stratis and Cirrus. More information is available on the official website: https://www.coinvault.io/ Smart City Platform Instance that is used to support the City Chain ecosystem, with focus on decentralized identity and citizenship in decentralized economies and communities. https://www.city-chain.org/", "title": "Extension"}, {"location": "extension/#extension", "text": "The Blockcore Extension is an web browser add-on that can be installed to give you an easy to use wallet. Extension can be built and distributed in multiple instances, making it possible to easily adopt the extension for different blockchains, ecosystems and purposes.", "title": "Extension"}, {"location": "extension/#blockcore-extension", "text": "This is the primary instance that has all features that exists. It's used for development, testing and verification of functionality.", "title": "Blockcore Extension"}, {"location": "extension/#coinvault", "text": "CoinVault is built for Stratis and Cirrus. More information is available on the official website: https://www.coinvault.io/", "title": "CoinVault"}, {"location": "extension/#smart-city-platform", "text": "Instance that is used to support the City Chain ecosystem, with focus on decentralized identity and citizenship in decentralized economies and communities. https://www.city-chain.org/", "title": "Smart City Platform"}, {"location": "extension/installation/", "text": "Extension: Installation Edge Add-on Store Availability later 2022 https://microsoftedge.microsoft.com/addons/Microsoft-Edge-Extensions-Home Chrome Web Store Availability later 2022 https://chrome.google.com/webstore/category/extensions GitHub Follow these instructions to manually install the extension. This allows you to test early releases and updates to the extension. These early releases can potentially have bugs, issues (report by clicking link) and problems. Download the extension package from releases . Download the blockcore-*.zip file to your local computer. Unpack the .zip file to a folder anywhere on your computer. Use a Chromium-based browser, like Brave, Edge, Chrome and others that supports extensions. Either find the extension page through the menu, or open this URL: edge://extensions/ chrome://extensions/ brave://extensions/ From the extension page in your browser, find the \"Developer mode\" toggle and turn it on. After developer mode has been turned on, new options appear. Click the Load unpacked . Locate the folder where you have unpacked the .zip file you downloaded earlier. The extension is now installed. When the extension is first installed, it will open up a new tab with the extension in full view model. You can pin the extension to the toolbar on your browser. Then you can easily access it through clicking the icon on the toolbar. Congratulations, you have successfully installed the extension and can continue by creating your new wallet.", "title": "Extension: Installation"}, {"location": "extension/installation/#extension-installation", "text": "", "title": "Extension: Installation"}, {"location": "extension/installation/#edge-add-on-store", "text": "Availability later 2022 https://microsoftedge.microsoft.com/addons/Microsoft-Edge-Extensions-Home", "title": "Edge Add-on Store"}, {"location": "extension/installation/#chrome-web-store", "text": "Availability later 2022 https://chrome.google.com/webstore/category/extensions", "title": "Chrome Web Store"}, {"location": "extension/installation/#github", "text": "Follow these instructions to manually install the extension. This allows you to test early releases and updates to the extension. These early releases can potentially have bugs, issues (report by clicking link) and problems. Download the extension package from releases . Download the blockcore-*.zip file to your local computer. Unpack the .zip file to a folder anywhere on your computer. Use a Chromium-based browser, like Brave, Edge, Chrome and others that supports extensions. Either find the extension page through the menu, or open this URL: edge://extensions/ chrome://extensions/ brave://extensions/ From the extension page in your browser, find the \"Developer mode\" toggle and turn it on. After developer mode has been turned on, new options appear. Click the Load unpacked . Locate the folder where you have unpacked the .zip file you downloaded earlier. The extension is now installed. When the extension is first installed, it will open up a new tab with the extension in full view model. You can pin the extension to the toolbar on your browser. Then you can easily access it through clicking the icon on the toolbar. Congratulations, you have successfully installed the extension and can continue by creating your new wallet.", "title": "GitHub"}, {"location": "faq/", "text": "Frequently Asked Questions and Common Issues This document contains a Table of contents to all FAQ and common issues. General FAQ What is Blockcore? Where can I get help and support? How can I contribute to Blockcore?", "title": "Frequently Asked Questions and Common Issues"}, {"location": "faq/#frequently-asked-questions-and-common-issues", "text": "This document contains a Table of contents to all FAQ and common issues.", "title": "Frequently Asked Questions and Common Issues"}, {"location": "faq/#general-faq", "text": "What is Blockcore? Where can I get help and support? How can I contribute to Blockcore?", "title": "General FAQ"}, {"location": "faq/faq-deployment/", "text": "Deployment", "title": "Deployment"}, {"location": "faq/faq-deployment/#deployment", "text": "", "title": "Deployment"}, {"location": "faq/faq-general/", "text": "General Blockcore FAQ This page contains general questions and answers about Blockcore. What it is, how it works, how to install it. General FAQ What is Blockcore? Where can I get help and support? How can I contribute to Blockcore? What is Blockcore? Blockcore is a free and open-source blockchain platform. Where can I get help and support? Blockcore is an open-source project. It is not a company; there is no e-mail, live-chat or phone support. The software relies on a network of contributors and users to provide support. If you encountered an issue or have a feature request, please open an issue on GitHub . For more general questions, join our community on Discord . Certain community members offer premium (paid) support . How can I contribute to Blockcore? There are many ways in which you can contribute to an open-source project like Blockcore. The easiest way is to use the software, provide feedback and report any bugs or issues you or your customers encounter. If you're a developer, you can help us develop and improve the software by contributing on the GitHub. Helping us with documentation writing are ways in which you can help us out, even if you're not a developer or tech-savvy. We appreciate every contributor to the project.", "title": "General"}, {"location": "faq/faq-general/#general-blockcore-faq", "text": "This page contains general questions and answers about Blockcore. What it is, how it works, how to install it.", "title": "General Blockcore FAQ"}, {"location": "faq/faq-general/#general-faq", "text": "What is Blockcore? Where can I get help and support? How can I contribute to Blockcore?", "title": "General FAQ"}, {"location": "faq/faq-general/#what-is-blockcore", "text": "Blockcore is a free and open-source blockchain platform.", "title": "What is Blockcore?"}, {"location": "faq/faq-general/#where-can-i-get-help-and-support", "text": "Blockcore is an open-source project. It is not a company; there is no e-mail, live-chat or phone support. The software relies on a network of contributors and users to provide support. If you encountered an issue or have a feature request, please open an issue on GitHub . For more general questions, join our community on Discord . Certain community members offer premium (paid) support .", "title": "Where can I get help and support?"}, {"location": "faq/faq-general/#how-can-i-contribute-to-blockcore", "text": "There are many ways in which you can contribute to an open-source project like Blockcore. The easiest way is to use the software, provide feedback and report any bugs or issues you or your customers encounter. If you're a developer, you can help us develop and improve the software by contributing on the GitHub. Helping us with documentation writing are ways in which you can help us out, even if you're not a developer or tech-savvy. We appreciate every contributor to the project.", "title": "How can I contribute to Blockcore?"}, {"location": "faq/faq-integrations/", "text": "Blockcore Integrations", "title": "Integrations"}, {"location": "faq/faq-integrations/#blockcore-integrations", "text": "", "title": "Blockcore Integrations"}, {"location": "faq/faq-synchronization/", "text": "Blockcore Synchronization Issues", "title": "Synchronization"}, {"location": "faq/faq-synchronization/#blockcore-synchronization-issues", "text": "", "title": "Blockcore Synchronization Issues"}, {"location": "faq/faq-wallet/", "text": "Blockcore Wallet (Node UI ) FAQ", "title": "Wallet"}, {"location": "faq/faq-wallet/#blockcore-wallet-node-ui-faq", "text": "", "title": "Blockcore Wallet (Node UI) FAQ"}, {"location": "node/api/", "text": "Node API The Blockcore node software exposes a few ports for different usages. There are three APIs available that can be consumed on a Blockcore based node, they are RPC, REST and Web Socket based. BEWARE: You should normally never expose these APIs to the public, they should be protected behind firewall. RPC API The RPC API is mainted to be compatible with Bitcoin Core and other chains that are forks or modifications of the original Bitcoin source code. REST API The REST API has more functionality and is continuously improved upon. You can use the OpenAPI documentation to investigate what functionality is available in the API. 1 http://localhost:PORT/docs/index.html WEB SOCKET API", "title": "Node API"}, {"location": "node/api/#node-api", "text": "The Blockcore node software exposes a few ports for different usages. There are three APIs available that can be consumed on a Blockcore based node, they are RPC, REST and Web Socket based. BEWARE: You should normally never expose these APIs to the public, they should be protected behind firewall.", "title": "Node API"}, {"location": "node/api/#rpc-api", "text": "The RPC API is mainted to be compatible with Bitcoin Core and other chains that are forks or modifications of the original Bitcoin source code.", "title": "RPC API"}, {"location": "node/api/#rest-api", "text": "The REST API has more functionality and is continuously improved upon. You can use the OpenAPI documentation to investigate what functionality is available in the API. 1 http://localhost:PORT/docs/index.html", "title": "REST API"}, {"location": "node/api/#web-socket-api", "text": "", "title": "WEB SOCKET API"}, {"location": "node/api/apiauthentication/", "text": "Node API: Authentication RPC API Authentication on the RPC API is done using basic authentication. You can configure the username and password in the .conf (ini) file or arguments when launching the node. REST API Authentication in the REST API is off by default. You should never expose your node to public traffic until after you enable authentication. By default, there are no authentication and no authorization on the REST API. Enable authentication by setting the \"enableAuth\" configuration value to true. *.conf file: 1 enableAuth = true API keys Access to your node is controlled using API keys. You can create / generate as many API keys as you need. Keys are stored in the appsettings.json file at the root of your node software. API keys are automatically refreshed while a node is running, so you can add, remove or edit these keys without restarting your node software. Example of API key: 1 2 3 4 5 6 7 8 9 10 11 12 13 \"Blockcore\" : { \"API\" : { \"Keys\" : [ { \"Id\" : 1 , \"Enabled\" : true , \"Owner\" : \"Admin\" , \"Key\" : \"1ca8f906-a23e-48b2-8b83-e95290986d0e\" , \"Roles\" : [ \"User\" , \"Admin\" ] } ] } } A key can be disabled by setting the \"Enabled\" value to false. This will immediately stop access using that API key. Roles There are currently two roles available, \"User\" and \"Admin\". Some API operations are only available to \"Admin\" role keys. Usage To use the REST API with your API keys, you must supply them as an HTTP HEADER with the key \"Node-Api-Key\". Testing from OpenAPI documentation Click the \"Authorize\" button, and enter the API key. Click \"Authorize\" to save the key, and now all calls from the documentation UI will include the API key in the header. Security risk Exposing your node software to the public and giving third parties, partners or users acecss using API keys is not without risk. The APIs can be used to shut down your node software (with \"Admin\" role), disconnect all connected peers through banning, and other operations that will make your node crash and non-functional.", "title": "Node API: Authentication"}, {"location": "node/api/apiauthentication/#node-api-authentication", "text": "", "title": "Node API: Authentication"}, {"location": "node/api/apiauthentication/#rpc-api", "text": "Authentication on the RPC API is done using basic authentication. You can configure the username and password in the .conf (ini) file or arguments when launching the node.", "title": "RPC API"}, {"location": "node/api/apiauthentication/#rest-api", "text": "Authentication in the REST API is off by default. You should never expose your node to public traffic until after you enable authentication. By default, there are no authentication and no authorization on the REST API. Enable authentication by setting the \"enableAuth\" configuration value to true. *.conf file: 1 enableAuth = true", "title": "REST API"}, {"location": "node/api/apiauthentication/#api-keys", "text": "Access to your node is controlled using API keys. You can create / generate as many API keys as you need. Keys are stored in the appsettings.json file at the root of your node software. API keys are automatically refreshed while a node is running, so you can add, remove or edit these keys without restarting your node software. Example of API key: 1 2 3 4 5 6 7 8 9 10 11 12 13 \"Blockcore\" : { \"API\" : { \"Keys\" : [ { \"Id\" : 1 , \"Enabled\" : true , \"Owner\" : \"Admin\" , \"Key\" : \"1ca8f906-a23e-48b2-8b83-e95290986d0e\" , \"Roles\" : [ \"User\" , \"Admin\" ] } ] } } A key can be disabled by setting the \"Enabled\" value to false. This will immediately stop access using that API key.", "title": "API keys"}, {"location": "node/api/apiauthentication/#roles", "text": "There are currently two roles available, \"User\" and \"Admin\". Some API operations are only available to \"Admin\" role keys.", "title": "Roles"}, {"location": "node/api/apiauthentication/#usage", "text": "To use the REST API with your API keys, you must supply them as an HTTP HEADER with the key \"Node-Api-Key\".", "title": "Usage"}, {"location": "node/api/apiauthentication/#testing-from-openapi-documentation", "text": "Click the \"Authorize\" button, and enter the API key. Click \"Authorize\" to save the key, and now all calls from the documentation UI will include the API key in the header.", "title": "Testing from OpenAPI documentation"}, {"location": "node/api/apiauthentication/#security-risk", "text": "Exposing your node software to the public and giving third parties, partners or users acecss using API keys is not without risk. The APIs can be used to shut down your node software (with \"Admin\" role), disconnect all connected peers through banning, and other operations that will make your node crash and non-functional.", "title": "Security risk"}, {"location": "node/api/apiauthorization/", "text": "Node API: Authorization RPC API There are no authorization built into the RPC API, all users have full access to all API methods. REST API The REST API have role based access control. Key and roles is controlled through the appsettings.json file. 1 \"Roles\" : [ \"User\" , \"Admin\" ] Authorization is handled through tags on controllers or operations. Here is example taken from the Shutdown operation, which is only accessible for admin keys: 1 2 3 4 5 6 7 8 9 [Authorize(Policy = \"OnlyAdmins\")] [HttpPost] [Route(\"shutdown\")] [Route(\"stop\")] public IActionResult Shutdown ([ FromBody ] bool corsProtection = true ) { this . fullNode ?. NodeLifetime . StopApplication (); return this . Ok (); } Unauthorized (401) When a request is not authorized with the API key, it will return an HTTP 401 Unauthorized result. If you get HTTP 500 error, that means there might be a configuration or other issues with the node. The JSON body result will be: 1 2 3 4 5 { \"type\" : \"https://httpstatuses.com/401\" , \"title\" : \"Unauthorized\" , \"status\" : 401 }", "title": "Node API: Authorization"}, {"location": "node/api/apiauthorization/#node-api-authorization", "text": "", "title": "Node API: Authorization"}, {"location": "node/api/apiauthorization/#rpc-api", "text": "There are no authorization built into the RPC API, all users have full access to all API methods.", "title": "RPC API"}, {"location": "node/api/apiauthorization/#rest-api", "text": "The REST API have role based access control. Key and roles is controlled through the appsettings.json file. 1 \"Roles\" : [ \"User\" , \"Admin\" ] Authorization is handled through tags on controllers or operations. Here is example taken from the Shutdown operation, which is only accessible for admin keys: 1 2 3 4 5 6 7 8 9 [Authorize(Policy = \"OnlyAdmins\")] [HttpPost] [Route(\"shutdown\")] [Route(\"stop\")] public IActionResult Shutdown ([ FromBody ] bool corsProtection = true ) { this . fullNode ?. NodeLifetime . StopApplication (); return this . Ok (); }", "title": "REST API"}, {"location": "node/api/apiauthorization/#unauthorized-401", "text": "When a request is not authorized with the API key, it will return an HTTP 401 Unauthorized result. If you get HTTP 500 error, that means there might be a configuration or other issues with the node. The JSON body result will be: 1 2 3 4 5 { \"type\" : \"https://httpstatuses.com/401\" , \"title\" : \"Unauthorized\" , \"status\" : 401 }", "title": "Unauthorized (401)"}, {"location": "node/features/", "text": "Features The Blockcore Node is built using extensible features. There are official features available, and third party features. Features is a way to dynamically load only what is needed for a node instance. For example to run an DNS node, one does not need the wallet feature.", "title": "Features"}, {"location": "node/features/#features", "text": "The Blockcore Node is built using extensible features. There are official features available, and third party features. Features is a way to dynamically load only what is needed for a node instance. For example to run an DNS node, one does not need the wallet feature.", "title": "Features"}, {"location": "node/features/airdrop/", "text": "Airdrop A helper tool for airdrops it can create UTXO snapshots and distribute coins. How to use the Airdrop feature The airdrop feature has two modes snapshot and distribute The Airdrop is considered to be a manual processes so it can be run in debug mode and some changes are applied directly to the code, such places are marked as Manual: in the distribute class. To enable the feature in the node builder register the feature itself similar to the bellow example. 1 2 3 4 5 6 7 8 var builder = new FullNodeBuilder() .UseNodeSettings(nodeSettings) .UseBlockStore() .UsePosConsensus() .UseColdStakingWallet() .UseApi() .UseMempool() .Airdrop(); Then run the node with either of the modes enabled. 1 2 To build the solution the relevant projects and daemon of the chain need to be referenced in the Blockcore.Features.Airdrop.sln file Snapshot Will take a snapshot of the UTXO set of a node and push this to a db to a table name UnspentOutputs . When the snapshot is running no new blocks will get validated (the consensus processes will block). To start the node in snapshot mode pass in the command arguments -snapshot -snapshotheight=[height] not if the node is passed the given height snapshot is ignored, to get the node back to a certain point in time debug the consensus code and manually override the ChainHeader that is the tip (in the future such a flag may be built in to the node). Once the snapshot is complete a file named snapshot-[height].db will appear in the nodes data folder. Distribute Will send coins from the local wallet to addresses that have been predefined in the table DistributeOutputs in the db this table needs to be populated in advance and it allows to prepare the addresses (and or script) that are going to be airdropped. A background worker will start and read the entries from the database then send coins to those entries. Currently the code will only create one trx with 500 outputs (this can be easily changed) and wait for that trx to get confirmed before processing the next batch. To start the node in snapshot mode pass in the command arguments -distribute -snapshotheight=[height] the snapshotheight is required to know the db filename. Steps how to start Run the airdrop tool on the source node in snapshot mode Copy the database to the target nodes data folder Edit the database and populate the table DistributeOutputs Run in airdrop tool on the target node in distribute mode Useful SQL Queries Group all outputs by address and sum the total value 1 2 3 4 5 6 SELECT Address, Script, ScriptType, count(Address), Sum(Value) as Value FROM UnspentOutputs WHERE Address != \"[address-to-ignore]\" AND Address != \"[address-to-ignore]\" GROUP BY Address ORDER By Sum(Value) DESC The total number of outputs and total value after the grouping 1 2 3 4 5 6 7 8 SELECT count(*), Sum(Value) FROM ( SELECT Address, Script, ScriptType, count(Address), Sum(Value) as Value FROM UnspentOutputs WHERE Address != \"[address-to-ignore]\" AND Address != \"[address-to-ignore]\" GROUP BY Address ORDER By Sum(Value) DESC ) Copy entries to the distribution table, this will contain all the addresses to airdrop on 1 2 3 4 5 6 7 INSERT INTO DistributeOutputs (Address, Script, ScriptType, Height, Value) SELECT Address, Script, ScriptType, 0, Sum(Value) as Value FROM UnspentOutputs WHERE Address != \"[address-to-ignore]\" AND Address != \"[address-to-ignore]\" GROUP BY Address ORDER By Sum(Value) DESC Follow progress of distribution 1 2 select status, count(status) FROM DistributeOutputs GROUP BY status Tool recommended to use is DB browser for SQLite", "title": "Airdrop"}, {"location": "node/features/airdrop/#airdrop", "text": "A helper tool for airdrops it can create UTXO snapshots and distribute coins.", "title": "Airdrop"}, {"location": "node/features/airdrop/#how-to-use-the-airdrop-feature", "text": "The airdrop feature has two modes snapshot and distribute The Airdrop is considered to be a manual processes so it can be run in debug mode and some changes are applied directly to the code, such places are marked as Manual: in the distribute class. To enable the feature in the node builder register the feature itself similar to the bellow example. 1 2 3 4 5 6 7 8 var builder = new FullNodeBuilder() .UseNodeSettings(nodeSettings) .UseBlockStore() .UsePosConsensus() .UseColdStakingWallet() .UseApi() .UseMempool() .Airdrop(); Then run the node with either of the modes enabled. 1 2 To build the solution the relevant projects and daemon of the chain need to be referenced in the Blockcore.Features.Airdrop.sln file", "title": "How to use the Airdrop feature"}, {"location": "node/features/airdrop/#snapshot", "text": "Will take a snapshot of the UTXO set of a node and push this to a db to a table name UnspentOutputs . When the snapshot is running no new blocks will get validated (the consensus processes will block). To start the node in snapshot mode pass in the command arguments -snapshot -snapshotheight=[height] not if the node is passed the given height snapshot is ignored, to get the node back to a certain point in time debug the consensus code and manually override the ChainHeader that is the tip (in the future such a flag may be built in to the node). Once the snapshot is complete a file named snapshot-[height].db will appear in the nodes data folder.", "title": "Snapshot"}, {"location": "node/features/airdrop/#distribute", "text": "Will send coins from the local wallet to addresses that have been predefined in the table DistributeOutputs in the db this table needs to be populated in advance and it allows to prepare the addresses (and or script) that are going to be airdropped. A background worker will start and read the entries from the database then send coins to those entries. Currently the code will only create one trx with 500 outputs (this can be easily changed) and wait for that trx to get confirmed before processing the next batch. To start the node in snapshot mode pass in the command arguments -distribute -snapshotheight=[height] the snapshotheight is required to know the db filename.", "title": "Distribute"}, {"location": "node/features/airdrop/#steps-how-to-start", "text": "Run the airdrop tool on the source node in snapshot mode Copy the database to the target nodes data folder Edit the database and populate the table DistributeOutputs Run in airdrop tool on the target node in distribute mode", "title": "Steps how to start"}, {"location": "node/features/airdrop/#useful-sql-queries", "text": "Group all outputs by address and sum the total value 1 2 3 4 5 6 SELECT Address, Script, ScriptType, count(Address), Sum(Value) as Value FROM UnspentOutputs WHERE Address != \"[address-to-ignore]\" AND Address != \"[address-to-ignore]\" GROUP BY Address ORDER By Sum(Value) DESC The total number of outputs and total value after the grouping 1 2 3 4 5 6 7 8 SELECT count(*), Sum(Value) FROM ( SELECT Address, Script, ScriptType, count(Address), Sum(Value) as Value FROM UnspentOutputs WHERE Address != \"[address-to-ignore]\" AND Address != \"[address-to-ignore]\" GROUP BY Address ORDER By Sum(Value) DESC ) Copy entries to the distribution table, this will contain all the addresses to airdrop on 1 2 3 4 5 6 7 INSERT INTO DistributeOutputs (Address, Script, ScriptType, Height, Value) SELECT Address, Script, ScriptType, 0, Sum(Value) as Value FROM UnspentOutputs WHERE Address != \"[address-to-ignore]\" AND Address != \"[address-to-ignore]\" GROUP BY Address ORDER By Sum(Value) DESC Follow progress of distribution 1 2 select status, count(status) FROM DistributeOutputs GROUP BY status Tool recommended to use is DB browser for SQLite", "title": "Useful SQL Queries"}, {"location": "node/features/blockexplorer/", "text": "Block Explorer (local) Local block explorer that can be used in combination with txindex=1 enabled on the node. This feature has API that allows the wallet UI to show block information locally. This enables full privacy blockchain insight. Local queries and index This feature builds a local index of the blockchain that you can search using the API interface. It gives full privacy in terms of what address or transactions you are looking up. This feature should not be mistaken for the Blockcore Explorer, which is a standalone software and can be made public available.", "title": "Block Explorer (local)"}, {"location": "node/features/blockexplorer/#block-explorer-local", "text": "Local block explorer that can be used in combination with txindex=1 enabled on the node. This feature has API that allows the wallet UI to show block information locally. This enables full privacy blockchain insight.", "title": "Block Explorer (local)"}, {"location": "node/features/blockexplorer/#local-queries-and-index", "text": "This feature builds a local index of the blockchain that you can search using the API interface. It gives full privacy in terms of what address or transactions you are looking up. This feature should not be mistaken for the Blockcore Explorer, which is a standalone software and can be made public available.", "title": "Local queries and index"}, {"location": "node/features/blockstore/", "text": "FeaturesBlockstore", "title": "FeaturesBlockstore"}, {"location": "node/features/blockstore/#featuresblockstore", "text": "", "title": "FeaturesBlockstore"}, {"location": "node/features/coldstaking/", "text": "FeaturesColdStaking", "title": "FeaturesColdStaking"}, {"location": "node/features/coldstaking/#featurescoldstaking", "text": "", "title": "FeaturesColdStaking"}, {"location": "node/features/consensus/", "text": "FeaturesConsensus", "title": "FeaturesConsensus"}, {"location": "node/features/consensus/#featuresconsensus", "text": "", "title": "FeaturesConsensus"}, {"location": "node/features/diagnostics/", "text": "FeaturesDiagnostics", "title": "FeaturesDiagnostics"}, {"location": "node/features/diagnostics/#featuresdiagnostics", "text": "", "title": "FeaturesDiagnostics"}, {"location": "node/features/dns/", "text": "FeaturesDns", "title": "FeaturesDns"}, {"location": "node/features/dns/#featuresdns", "text": "", "title": "FeaturesDns"}, {"location": "node/features/memorypool/", "text": "FeaturesMemoryPool", "title": "FeaturesMemoryPool"}, {"location": "node/features/memorypool/#featuresmemorypool", "text": "", "title": "FeaturesMemoryPool"}, {"location": "node/features/miner/", "text": "FeaturesMiner Blockcore has built in PoW and PoS miners.", "title": "FeaturesMiner"}, {"location": "node/features/miner/#featuresminer", "text": "Blockcore has built in PoW and PoS miners.", "title": "FeaturesMiner"}, {"location": "node/features/nodehost/", "text": "FeaturesNodeHost", "title": "FeaturesNodeHost"}, {"location": "node/features/nodehost/#featuresnodehost", "text": "", "title": "FeaturesNodeHost"}, {"location": "node/features/notifications/", "text": "FeaturesNotifications", "title": "FeaturesNotifications"}, {"location": "node/features/notifications/#featuresnotifications", "text": "", "title": "FeaturesNotifications"}, {"location": "node/features/poa/", "text": "FeaturesPoA", "title": "FeaturesPoA"}, {"location": "node/features/poa/#featurespoa", "text": "", "title": "FeaturesPoA"}, {"location": "node/features/rpc/", "text": "FeaturesRPC", "title": "FeaturesRPC"}, {"location": "node/features/rpc/#featuresrpc", "text": "", "title": "FeaturesRPC"}, {"location": "node/features/storage/", "text": "Features: Storage The storage feature is an feature that enables nodes to synchronize and store documents. It has structured handling of some document types and supports generic data storage. Use case The use case for storage is a way to have a decentralized and distributed storage mechanism for data. The primary data type is text based documents in JSON format. Documents must be signed by the original author and the signature must be included with the document for verification. Data can be stored unencrypted and encrypted. One example of use case is storing the personal contact list. This is something that typically would be stored encrypted and not readable by third parties. Another example of use case is storing awards and certifications received, which can be used to lookup and verify completed courses and valid certifications. API Most interactions with the storage feature is done through REST API that is made public available. It is also possible to run your own local node with the storage feature enabled. Nodes that are public, are refered to as hubs. Identities The main artefact of the storage feature, is identity. Identities are always synchronized across nodes. They are free of charge by users who use the APIs. There is limit to fields that are allowed and length of the fields on the identity. Since the identities are free and shared across all nodes, they must be limited. Everything is connected to the identities. A person can have one or multiple identities. A person can also make identities for their business entities and other resources, such as servers, hubs and more. Your identities is the foundation of secure messaging, for verification and social networking and a lot more. Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"version\" : 1 , \"id\" : \"identity/P9ppftn667PgXwqCKNaUVnD8BS8rjmkcUo\" , \"signature\" : \"ICSoxi6ScRYozMeDGU0+gZAltyis27mUA16JeAT2u24xSH23LEaAKwXJjv4dbWPhvfZbTFmr/fy7/MWTbXpgdDY=\" , \"content\" : { \"identifier\" : \"P9ppftn667PgXwqCKNaUVnD8BS8rjmkcUo\" , \"height\" : 1 , \"name\" : \"Sondre Bjell\u00e5s\" , \"shortName\" : \"SondreB\" , \"alias\" : \"Vanarki\" , \"title\" : null , \"email\" : \"sondre@outlook.com\" , \"url\" : \"https://www.sondreb.com\" , \"image\" : \"https://avatars1.githubusercontent.com/u/309938?s=460&u=c82ed1827100905dc561460fdfc68ca463b29194&v=4\" , \"hubs\" : null } } The \"id\" on the \"container\" is based on the container and the identifier in the content. The \"content\" is what consititutes the \"document\" and is signed. The \"container\" is not verified and can be modified by the nodes indiscriminately. You can only trust the \"content\", not the \"container\". The \"content/hubs\" is a list of identifiers of hubs that the user uses to store their data. As mentioned before, identities is shared across all nodes, but identity is the only data that is shared like this. Other data is stored on specific hubs. Data Data other than the identities is normally retrieved from known hubs. If for example the \"image\" field on the identity contains a relative path, it means that the image is stored on the hubs. Example: 1 2 3 4 5 6 { \"content\" : { \"identifier\" : \"P9ppftn667PgXwqCKNaUVnD8BS8rjmkcUo\" , \"image\" : \"data/jysdfzx234.jpg\" , \"hubs\" : [ \"P4xYftn667PgXwqCKNaUVnD8BS8rjmkcUo\" ] } In the example above, the profile image can be retrieved using the following actions: Query the identity API for the identity of the hub. Get the \"url\" of the hub identity, e.g. \"https://city.hub.blockcore.net\". Combine the URL of the hub with the relative path, e.g. \"https://city.hub.blockcore.net/data/jysdfzx234.jpg\" Then you can either download that image, or show it to the users of your app. Data structures are always stored under the identifier of an identity. Remember that identities is not just human beings, it can also be pets, hubs, servers and applications. If you develop your own application named \"CuteCatPhotos\" which is a collection of links to externally hosted photos, your storage path might be: /data/P1ppftn667PgXwqCKNaUVnD8BS8rjmkcUo/ When a user interacts with your application, content created might be stored under the identity of your application, or it might be stored under their own identity. /data/P9ppftn667PgXwqCKNaUVnD8BS8rjmkcUo/ If data is stored under the identity of the user, it means that the user owns the data and is the only one that can edit or remove the data. When the data is stored under the identity of the app, data can be updated by either the app, but also by the user, depending on how the application is developed. Payment Data is stored on hubs and these are either free of charge, or based on agreements. Anyone can host their own hub if they want to. Users can sign up and pay for subscriptions to a hub through various means, and then user management happens with API keys that the hub owner manages. Last option is to utilize hubs that is built around automatic invoicing. These will invoice the identity on a regular interval for the amount of traffic and storage that is being consumed. If the user does not pay the invoice, their data might be deleted off the hub. This means that there are limitless options on how to do payment for storage, compared to blockchain based storage solutions that uses transaction fees. Payment like described here allows anyone to begin develop Web3 applications and use the storage functionality without the use of wallet and cryptocurrency. Signing Identities are a known type and must follow a strict set of schema. This class must be marked with the [MessagePackObject] attribute. Each of the properties must be marked with a fixed order, with attribute like [Key(0)]. When signing a document (\"content\"), you must first serialize your document using an Message Pack serializer. These are available for different languages and platforms, including JavaScript. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // Example on how to derive the key pair needed for an identity. string recoveryPhrase = \"mystery problem faith negative member bottom concert bundle asthma female process twelve\" ; var mnemonic = new Mnemonic ( recoveryPhrase ); ExtKey masterNode = mnemonic . DeriveExtKey (); ExtKey identityRoot = masterNode . Derive ( new KeyPath ( \"m/302'\" )); ExtKey identity = identityRoot . Derive ( 0 , true ); // Create an identity profile that should be signed and published. Identity identityModel = new Identity { Identifier = identity0Id , Name = \"John Doe\" , ShortName = \"John\" , Alias = \"JD\" , Title = \"Hi.\" , Url = \"https://\" , Image = \"https://\" , Height = 10 , Hubs = new string [ 1 ] { \"PN9Gibo37UzogRC2cBxymvBtbM2p5eNfWi\" } }; // Serialize to MessagePack. byte [] entityBytes = MessagePackSerializer . Serialize ( identityModel ); string signature = identity . PrivateKey . SignMessage ( entityBytes ); // Encapsulate the identity into a container var identityContainer = new IdentityDocument { Id = \"identity/\" + identityModel . Identifier , Content = identityModel , Signature = signature }; // Publish to local node or public hub. Verification Verification is done by redoing the message pack serialization, then checking to verify if the signature was signed with the private key of the public key (the identifier). 1 2 3 4 5 6 byte [] entityBytes = MessagePackSerializer . Serialize ( document . Content ); // You need a reference to the ProfileNetwork. var bitcoinAddress = ( BitcoinPubKeyAddress ) BitcoinPubKeyAddress . Create ( address , ProfileNetwork . Instance ); var valid = bitcoinAddress . VerifyMessage ( entityBytes , document . Signature ); Synchronization When nodes connect they will begin to exchange the signatures of all documents. This is done in chunks. As each node process the signatures of the other node, it will ask to retrieve documents that it is missing. When the document is retrieved based on the signature, the document is serialized and signature is verified. If everything is OK, then the height is used to validate if the received document is older or newer than the current. When a hub (node) receives a new or updated document through the REST API, it will immediately distribute the document to connected peers (nodes). A node that receives new/updated documents in full based on this push action, will forward a notification to all if its connected nodes with the signature it received. This ensures that there won't be duplicate transfer of documents and that newly observed documents are quickly distributed across the nodes. Node A connects with Node B Both send StoragePayload with list of supported collections and request to get signatures. Both send StorageInvPayload with list of signatures in each of the collections supported. When node discover a signature that is not available locally, it sends a StoragePayload request to retrieve the missing document. When node receives missing document, it verifies if document is old or new version of existing document. Not implemented yet: The final step is to perform a verification of synchronized state, if both nodes has the same set of data. Versioning The root document has a version attribute, and the node has built into it a minimum version and maximum version of known document types and the generic document type. If an unsupported document is received, nothing will happen. The document will not be persisted. Please note that the version on the container of the document, is not a revision number of the document itself. It is used for type compatibility checking.", "title": "Features: Storage"}, {"location": "node/features/storage/#features-storage", "text": "The storage feature is an feature that enables nodes to synchronize and store documents. It has structured handling of some document types and supports generic data storage.", "title": "Features: Storage"}, {"location": "node/features/storage/#use-case", "text": "The use case for storage is a way to have a decentralized and distributed storage mechanism for data. The primary data type is text based documents in JSON format. Documents must be signed by the original author and the signature must be included with the document for verification. Data can be stored unencrypted and encrypted. One example of use case is storing the personal contact list. This is something that typically would be stored encrypted and not readable by third parties. Another example of use case is storing awards and certifications received, which can be used to lookup and verify completed courses and valid certifications.", "title": "Use case"}, {"location": "node/features/storage/#api", "text": "Most interactions with the storage feature is done through REST API that is made public available. It is also possible to run your own local node with the storage feature enabled. Nodes that are public, are refered to as hubs.", "title": "API"}, {"location": "node/features/storage/#identities", "text": "The main artefact of the storage feature, is identity. Identities are always synchronized across nodes. They are free of charge by users who use the APIs. There is limit to fields that are allowed and length of the fields on the identity. Since the identities are free and shared across all nodes, they must be limited. Everything is connected to the identities. A person can have one or multiple identities. A person can also make identities for their business entities and other resources, such as servers, hubs and more. Your identities is the foundation of secure messaging, for verification and social networking and a lot more. Example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 { \"version\" : 1 , \"id\" : \"identity/P9ppftn667PgXwqCKNaUVnD8BS8rjmkcUo\" , \"signature\" : \"ICSoxi6ScRYozMeDGU0+gZAltyis27mUA16JeAT2u24xSH23LEaAKwXJjv4dbWPhvfZbTFmr/fy7/MWTbXpgdDY=\" , \"content\" : { \"identifier\" : \"P9ppftn667PgXwqCKNaUVnD8BS8rjmkcUo\" , \"height\" : 1 , \"name\" : \"Sondre Bjell\u00e5s\" , \"shortName\" : \"SondreB\" , \"alias\" : \"Vanarki\" , \"title\" : null , \"email\" : \"sondre@outlook.com\" , \"url\" : \"https://www.sondreb.com\" , \"image\" : \"https://avatars1.githubusercontent.com/u/309938?s=460&u=c82ed1827100905dc561460fdfc68ca463b29194&v=4\" , \"hubs\" : null } } The \"id\" on the \"container\" is based on the container and the identifier in the content. The \"content\" is what consititutes the \"document\" and is signed. The \"container\" is not verified and can be modified by the nodes indiscriminately. You can only trust the \"content\", not the \"container\". The \"content/hubs\" is a list of identifiers of hubs that the user uses to store their data. As mentioned before, identities is shared across all nodes, but identity is the only data that is shared like this. Other data is stored on specific hubs.", "title": "Identities"}, {"location": "node/features/storage/#data", "text": "Data other than the identities is normally retrieved from known hubs. If for example the \"image\" field on the identity contains a relative path, it means that the image is stored on the hubs. Example: 1 2 3 4 5 6 { \"content\" : { \"identifier\" : \"P9ppftn667PgXwqCKNaUVnD8BS8rjmkcUo\" , \"image\" : \"data/jysdfzx234.jpg\" , \"hubs\" : [ \"P4xYftn667PgXwqCKNaUVnD8BS8rjmkcUo\" ] } In the example above, the profile image can be retrieved using the following actions: Query the identity API for the identity of the hub. Get the \"url\" of the hub identity, e.g. \"https://city.hub.blockcore.net\". Combine the URL of the hub with the relative path, e.g. \"https://city.hub.blockcore.net/data/jysdfzx234.jpg\" Then you can either download that image, or show it to the users of your app. Data structures are always stored under the identifier of an identity. Remember that identities is not just human beings, it can also be pets, hubs, servers and applications. If you develop your own application named \"CuteCatPhotos\" which is a collection of links to externally hosted photos, your storage path might be: /data/P1ppftn667PgXwqCKNaUVnD8BS8rjmkcUo/ When a user interacts with your application, content created might be stored under the identity of your application, or it might be stored under their own identity. /data/P9ppftn667PgXwqCKNaUVnD8BS8rjmkcUo/ If data is stored under the identity of the user, it means that the user owns the data and is the only one that can edit or remove the data. When the data is stored under the identity of the app, data can be updated by either the app, but also by the user, depending on how the application is developed.", "title": "Data"}, {"location": "node/features/storage/#payment", "text": "Data is stored on hubs and these are either free of charge, or based on agreements. Anyone can host their own hub if they want to. Users can sign up and pay for subscriptions to a hub through various means, and then user management happens with API keys that the hub owner manages. Last option is to utilize hubs that is built around automatic invoicing. These will invoice the identity on a regular interval for the amount of traffic and storage that is being consumed. If the user does not pay the invoice, their data might be deleted off the hub. This means that there are limitless options on how to do payment for storage, compared to blockchain based storage solutions that uses transaction fees. Payment like described here allows anyone to begin develop Web3 applications and use the storage functionality without the use of wallet and cryptocurrency.", "title": "Payment"}, {"location": "node/features/storage/#signing", "text": "Identities are a known type and must follow a strict set of schema. This class must be marked with the [MessagePackObject] attribute. Each of the properties must be marked with a fixed order, with attribute like [Key(0)]. When signing a document (\"content\"), you must first serialize your document using an Message Pack serializer. These are available for different languages and platforms, including JavaScript. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // Example on how to derive the key pair needed for an identity. string recoveryPhrase = \"mystery problem faith negative member bottom concert bundle asthma female process twelve\" ; var mnemonic = new Mnemonic ( recoveryPhrase ); ExtKey masterNode = mnemonic . DeriveExtKey (); ExtKey identityRoot = masterNode . Derive ( new KeyPath ( \"m/302'\" )); ExtKey identity = identityRoot . Derive ( 0 , true ); // Create an identity profile that should be signed and published. Identity identityModel = new Identity { Identifier = identity0Id , Name = \"John Doe\" , ShortName = \"John\" , Alias = \"JD\" , Title = \"Hi.\" , Url = \"https://\" , Image = \"https://\" , Height = 10 , Hubs = new string [ 1 ] { \"PN9Gibo37UzogRC2cBxymvBtbM2p5eNfWi\" } }; // Serialize to MessagePack. byte [] entityBytes = MessagePackSerializer . Serialize ( identityModel ); string signature = identity . PrivateKey . SignMessage ( entityBytes ); // Encapsulate the identity into a container var identityContainer = new IdentityDocument { Id = \"identity/\" + identityModel . Identifier , Content = identityModel , Signature = signature }; // Publish to local node or public hub.", "title": "Signing"}, {"location": "node/features/storage/#verification", "text": "Verification is done by redoing the message pack serialization, then checking to verify if the signature was signed with the private key of the public key (the identifier). 1 2 3 4 5 6 byte [] entityBytes = MessagePackSerializer . Serialize ( document . Content ); // You need a reference to the ProfileNetwork. var bitcoinAddress = ( BitcoinPubKeyAddress ) BitcoinPubKeyAddress . Create ( address , ProfileNetwork . Instance ); var valid = bitcoinAddress . VerifyMessage ( entityBytes , document . Signature );", "title": "Verification"}, {"location": "node/features/storage/#synchronization", "text": "When nodes connect they will begin to exchange the signatures of all documents. This is done in chunks. As each node process the signatures of the other node, it will ask to retrieve documents that it is missing. When the document is retrieved based on the signature, the document is serialized and signature is verified. If everything is OK, then the height is used to validate if the received document is older or newer than the current. When a hub (node) receives a new or updated document through the REST API, it will immediately distribute the document to connected peers (nodes). A node that receives new/updated documents in full based on this push action, will forward a notification to all if its connected nodes with the signature it received. This ensures that there won't be duplicate transfer of documents and that newly observed documents are quickly distributed across the nodes. Node A connects with Node B Both send StoragePayload with list of supported collections and request to get signatures. Both send StorageInvPayload with list of signatures in each of the collections supported. When node discover a signature that is not available locally, it sends a StoragePayload request to retrieve the missing document. When node receives missing document, it verifies if document is old or new version of existing document. Not implemented yet: The final step is to perform a verification of synchronized state, if both nodes has the same set of data.", "title": "Synchronization"}, {"location": "node/features/storage/#versioning", "text": "The root document has a version attribute, and the node has built into it a minimum version and maximum version of known document types and the generic document type. If an unsupported document is received, nothing will happen. The document will not be persisted. Please note that the version on the container of the document, is not a revision number of the document itself. It is used for type compatibility checking.", "title": "Versioning"}, {"location": "node/features/wallet/", "text": "FeaturesWallet", "title": "FeaturesWallet"}, {"location": "node/features/wallet/#featureswallet", "text": "", "title": "FeaturesWallet"}, {"location": "node/features/walletnotify/", "text": "Wallet Notify Adds the ability to perform shell executions when transactions is observed in the wallet. How to use the Wallet Notify feature To enable the feature in the node builder register the feature itself similar to the bellow example. 1 2 3 4 5 6 7 8 var builder = new FullNodeBuilder() .UseNodeSettings(nodeSettings) .UseBlockStore() .UsePosConsensus() .UseColdStakingWallet() .UseApi() .UseMempool() .UseWalletNotify(); # This is how to enable wallet notify Setting the shell command Provide the -walletnotify argument, either as argument parameter on startup, or by editing the blockcore.conf file. In the command, the value \"%s\" will be replaced with the transaction ID. Example: 1 -walletnotify=\\\"curl -X POST -d txid=%s http://localhost:5000/\\\" When is the notifier triggered? When an transaction is observed in the mempool, the notifier is run once. It is run again when the same transaction is included in a block. When a rescan of the wallet is performed, it will re-run the notifier, but only once pr. transaction since the transactions are already in blocks.", "title": "Wallet Notify"}, {"location": "node/features/walletnotify/#wallet-notify", "text": "Adds the ability to perform shell executions when transactions is observed in the wallet.", "title": "Wallet Notify"}, {"location": "node/features/walletnotify/#how-to-use-the-wallet-notify-feature", "text": "To enable the feature in the node builder register the feature itself similar to the bellow example. 1 2 3 4 5 6 7 8 var builder = new FullNodeBuilder() .UseNodeSettings(nodeSettings) .UseBlockStore() .UsePosConsensus() .UseColdStakingWallet() .UseApi() .UseMempool() .UseWalletNotify(); # This is how to enable wallet notify", "title": "How to use the Wallet Notify feature"}, {"location": "node/features/walletnotify/#setting-the-shell-command", "text": "Provide the -walletnotify argument, either as argument parameter on startup, or by editing the blockcore.conf file. In the command, the value \"%s\" will be replaced with the transaction ID. Example: 1 -walletnotify=\\\"curl -X POST -d txid=%s http://localhost:5000/\\\"", "title": "Setting the shell command"}, {"location": "node/features/walletnotify/#when-is-the-notifier-triggered", "text": "When an transaction is observed in the mempool, the notifier is run once. It is run again when the same transaction is included in a block. When a rescan of the wallet is performed, it will re-run the notifier, but only once pr. transaction since the transactions are already in blocks.", "title": "When is the notifier triggered?"}, {"location": "node/features/walletwatchonly/", "text": "FeaturesWalletWatchOnly", "title": "FeaturesWalletWatchOnly"}, {"location": "node/features/walletwatchonly/#featureswalletwatchonly", "text": "", "title": "FeaturesWalletWatchOnly"}, {"location": "node/p2p/", "text": "Peer to Peer The Blockcore node software has implemented the same peer to peer protocol as Bitcoin Core. This protocol is used to synchronize blocks, transactions, memory pool and more. Data sent between nodes is messages that encapsulates payloads .", "title": "Peer to Peer"}, {"location": "node/p2p/#peer-to-peer", "text": "The Blockcore node software has implemented the same peer to peer protocol as Bitcoin Core. This protocol is used to synchronize blocks, transactions, memory pool and more. Data sent between nodes is messages that encapsulates payloads .", "title": "Peer to Peer"}, {"location": "node/p2p/payloads/", "text": "Payloads Standard payloads Built into the Blockcore foundation there are some payloads used to handle the peer to peer protocol and connections of nodes, and exchange of blockchain data. Here are the built in primary payload types with their command names in parentheses: AddrPayload (\"addr\") BlockPayload (\"block\") GetAddrPayload (\"getaddr\") GetBlocksPayload (\"getblocks\") GetDataPayload (\"getdata\") GetHeadersPayload (\"getheaders\") GetProvenHeadersPayload (\"getprovhdr\") HaveWitnessPayload (\"havewitness\") HeadersPayload (\"headers\") InvPayload (\"inv\") MempoolPayload (\"mempool\") NotFoundPayload PingPayload (\"ping\") PongPayload (\"pong\") ProvenHeadersPayload (\"provhdr\") RejectPayload (\"reject\") SendHeadersPayload (\"sendheaders\") TxPayload (\"tx\") UnknowPayload VerAckPayload (\"verack\") VersionPayload (\"version\") Here are payload types defined in features: FeeFilterPayload (\"feefilter\") PoAHeaderPayload (\"poahdr\") StoragePayload (\"storage\") StorageInvPayload (\"storageinv\") Here is a code map of the payload in the Blockcore assembly: Here is a code map of the custom payload types defined in features: Your own custom payload You can implement your own custom payloads, which is a great way to build a communication solution between nodes connected in a peer to peer fashion. You can use these custom features to build chat solutions, data transfer solutions or any other logic that can be useful for a network of nodes. All you need is one or multiple payload types and an behavior class. Example of a payload. You should define these classes inside your own custom feature. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // This sample is copied from the \"ping\" payload. using NBitcoin ; namespace Blockcore.P2P.Protocol.Payloads { [Payload(\"storage\")] public class StoragePayload : Payload { private uint [] items ; public uint [] Items { get { return this . items ; } set { this . items = value ; } } public StoragePayload ( uint [] items ) { this . items = items ; } public override void ReadWriteCore ( BitcoinStream stream ) { stream . ReadWrite ( ref this . items ); } public override string ToString () { return base . ToString () + \" : \" + this . Items ; } } } Then you also need a behavior that will process messages. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 using System ; using System.Collections.Generic ; using System.Linq ; using System.Threading.Tasks ; using Blockcore.Connection ; using Blockcore.Interfaces ; using Blockcore.P2P.Peer ; using Blockcore.P2P.Protocol ; using Blockcore.P2P.Protocol.Behaviors ; using Blockcore.P2P.Protocol.Payloads ; using Blockcore.Signals ; using Blockcore.Utilities ; using Microsoft.Extensions.Logging ; using NBitcoin ; namespace Blockcore.Features.Storage { /// <summary> /// Peer behavior for memory pool. /// Provides message handling of notifications from attached peer. /// </summary> public class StorageBehavior : NetworkPeerBehavior { /// <summary>Connection manager for managing peer connections.</summary> private readonly IConnectionManager connectionManager ; /// <summary>Provider of IBD state.</summary> private readonly IInitialBlockDownloadState initialBlockDownloadState ; /// <summary>Instance logger for the memory pool behavior component.</summary> private readonly ILogger logger ; /// <summary>Factory used to create the logger for this component.</summary> private readonly ILoggerFactory loggerFactory ; /// <summary>The network that this component is running on.</summary> private readonly Network network ; /// <summary> /// Locking object for memory pool behaviour. /// </summary> private readonly object lockObject ; /// <summary> /// The min fee the peer asks to relay transactions. /// </summary> public Money MinFeeFilter { get ; set ; } public StorageBehavior ( IConnectionManager connectionManager , IInitialBlockDownloadState initialBlockDownloadState , ILoggerFactory loggerFactory , Network network ) { this . connectionManager = connectionManager ; this . initialBlockDownloadState = initialBlockDownloadState ; this . logger = loggerFactory . CreateLogger ( this . GetType (). FullName ); this . loggerFactory = loggerFactory ; this . network = network ; this . lockObject = new object (); } /// <inheritdoc /> protected override void AttachCore () { this . AttachedPeer . MessageReceived . Register ( this . OnMessageReceivedAsync ); } /// <inheritdoc /> protected override void DetachCore () { this . AttachedPeer . MessageReceived . Unregister ( this . OnMessageReceivedAsync ); } /// <inheritdoc /> public override object Clone () { return new StorageBehavior ( this . connectionManager , this . initialBlockDownloadState , this . loggerFactory , this . network ); } private async Task OnMessageReceivedAsync ( INetworkPeer peer , IncomingMessage message ) { try { await this . ProcessMessageAsync ( peer , message ). ConfigureAwait ( false ); } catch ( OperationCanceledException ) { this . logger . LogTrace ( \"(-)[CANCELED_EXCEPTION]\" ); return ; } catch ( Exception ex ) { this . logger . LogError ( \"Exception occurred: {0}\" , ex . ToString ()); throw ; } } private async Task ProcessMessageAsync ( INetworkPeer peer , IncomingMessage message ) { try { switch ( message . Message . Payload ) { case StoragePayload storagePayload : await this . ProcessStorageInPayloadAsync ( peer , storagePayload ). ConfigureAwait ( false ); break ; } } catch ( OperationCanceledException ) { this . logger . LogTrace ( \"(-)[CANCELED_EXCEPTION]\" ); return ; } } private async Task ProcessStorageInPayloadAsync ( INetworkPeer peer , StoragePayload message ) { Guard . NotNull ( peer , nameof ( peer )); if ( peer != this . AttachedPeer ) { this . logger . LogDebug ( \"Attached peer '{0}' does not match the originating peer '{1}'.\" , this . AttachedPeer ?. RemoteSocketEndpoint , peer . RemoteSocketEndpoint ); this . logger . LogTrace ( \"(-)[PEER_MISMATCH]\" ); return ; } List < uint > list = new List < uint >(); list . Add ( 1 ); list . Add ( 2 ); list . Add ( 3 ); await this . SendStorageAsync ( peer , list ); } private async Task SendStorageAsync ( INetworkPeer peer , List < uint > storageList ) { var queue = new Queue < uint >( storageList ); while ( queue . Count > 0 ) { uint [] items = queue . TakeAndRemove ( 5 ). ToArray (); if ( peer . IsConnected ) { this . logger . LogDebug ( \"Sending items to peer '{0}'.\" , peer . RemoteSocketEndpoint ); await peer . SendMessageAsync ( new StoragePayload ( items )). ConfigureAwait ( false ); } } } public async Task SendTrickleAsync () { INetworkPeer peer = this . AttachedPeer ; if ( peer == null ) { this . logger . LogTrace ( \"(-)[NO_PEER]\" ); return ; } this . logger . LogDebug ( \"Sending storage inventory to peer '{0}'.\" , peer . RemoteSocketEndpoint ); try { // Sample data to send. List < uint > list = new List < uint >(); list . Add ( 1 ); list . Add ( 2 ); await this . SendStorageAsync ( peer , list ). ConfigureAwait ( false ); } catch ( OperationCanceledException ) { this . logger . LogTrace ( \"(-)[CANCELED_EXCEPTION]\" ); return ; } } } } Then finally you need your custom feature: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 using System.Collections.Generic ; using System.Linq ; using System.Threading.Tasks ; using Blockcore.AsyncWork ; using Blockcore.Builder ; using Blockcore.Builder.Feature ; using Blockcore.Configuration.Logging ; using Blockcore.Connection ; using Blockcore.Features.Storage.Persistence ; using Blockcore.P2P.Peer ; using Blockcore.P2P.Protocol.Payloads ; using Blockcore.Utilities ; using Microsoft.Extensions.DependencyInjection ; namespace Blockcore.Features.Storage { public class StorageFeature : FullNodeFeature { /// <summary>The async loop we need to wait upon before we can shut down this manager.</summary> private IAsyncLoop asyncLoop ; /// <summary>Factory for creating background async loop tasks.</summary> private readonly IAsyncProvider asyncProvider ; /// <summary> /// Connection manager injected dependency. /// </summary> private readonly IConnectionManager connection ; /// <summary>Global application life cycle control - triggers when application shuts down.</summary> private readonly INodeLifetime nodeLifetime ; private readonly PayloadProvider payloadProvider ; private readonly StorageBehavior storageBehavior ; public StorageFeature ( IConnectionManager connection , INodeLifetime nodeLifetime , IAsyncProvider asyncProvider , PayloadProvider payloadProvider , StorageBehavior storageBehavior ) { this . connection = connection ; this . nodeLifetime = nodeLifetime ; this . payloadProvider = payloadProvider ; this . asyncProvider = asyncProvider ; this . storageBehavior = storageBehavior ; } public override Task InitializeAsync () { // Register the behavior. this . connection . Parameters . TemplateBehaviors . Add ( this . storageBehavior ); // Register the payload types. this . payloadProvider . AddPayload ( typeof ( StoragePayload )); // Make a worker that will filter connected knows that has announced our custom payload behavior. this . asyncLoop = this . asyncProvider . CreateAndRunAsyncLoop ( \"Storage.SyncWorker\" , async token => { IReadOnlyNetworkPeerCollection peers = this . connection . ConnectedPeers ; if (! peers . Any ()) { return ; } // Announce the blocks on each nodes behavior which supports relaying. IEnumerable < StorageBehavior > behaviors = peers . Where ( x => x . PeerVersion ?. Relay ?? false ) . Select ( x => x . Behavior < StorageBehavior >()) . Where ( x => x != null ) . ToList (); foreach ( StorageBehavior behavior in behaviors ) { await behavior . SendTrickleAsync (). ConfigureAwait ( false ); } }, this . nodeLifetime . ApplicationStopping , repeatEvery : TimeSpans . FiveSeconds , startAfter : TimeSpans . TenSeconds ); return Task . CompletedTask ; } } /// <summary> /// A class providing extension methods for <see cref=\"IFullNodeBuilder\"/>. /// </summary> public static class FullNodeBuilderStorageExtension { public static IFullNodeBuilder UseStorage ( this IFullNodeBuilder fullNodeBuilder ) { LoggingConfiguration . RegisterFeatureNamespace < StorageFeature >( \"storage\" ); fullNodeBuilder . ConfigureFeature ( features => { features . AddFeature < StorageFeature >() . FeatureServices ( services => { services . AddSingleton < IDataStore , DataStore >(); services . AddSingleton < StorageBehavior >(); }); }); return fullNodeBuilder ; } } } This is basically all you need to start building custom data payload features ontop of your network of Blockcore nodes.", "title": "Payloads"}, {"location": "node/p2p/payloads/#payloads", "text": "", "title": "Payloads"}, {"location": "node/p2p/payloads/#standard-payloads", "text": "Built into the Blockcore foundation there are some payloads used to handle the peer to peer protocol and connections of nodes, and exchange of blockchain data. Here are the built in primary payload types with their command names in parentheses: AddrPayload (\"addr\") BlockPayload (\"block\") GetAddrPayload (\"getaddr\") GetBlocksPayload (\"getblocks\") GetDataPayload (\"getdata\") GetHeadersPayload (\"getheaders\") GetProvenHeadersPayload (\"getprovhdr\") HaveWitnessPayload (\"havewitness\") HeadersPayload (\"headers\") InvPayload (\"inv\") MempoolPayload (\"mempool\") NotFoundPayload PingPayload (\"ping\") PongPayload (\"pong\") ProvenHeadersPayload (\"provhdr\") RejectPayload (\"reject\") SendHeadersPayload (\"sendheaders\") TxPayload (\"tx\") UnknowPayload VerAckPayload (\"verack\") VersionPayload (\"version\") Here are payload types defined in features: FeeFilterPayload (\"feefilter\") PoAHeaderPayload (\"poahdr\") StoragePayload (\"storage\") StorageInvPayload (\"storageinv\") Here is a code map of the payload in the Blockcore assembly: Here is a code map of the custom payload types defined in features:", "title": "Standard payloads"}, {"location": "node/p2p/payloads/#your-own-custom-payload", "text": "You can implement your own custom payloads, which is a great way to build a communication solution between nodes connected in a peer to peer fashion. You can use these custom features to build chat solutions, data transfer solutions or any other logic that can be useful for a network of nodes. All you need is one or multiple payload types and an behavior class. Example of a payload. You should define these classes inside your own custom feature. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // This sample is copied from the \"ping\" payload. using NBitcoin ; namespace Blockcore.P2P.Protocol.Payloads { [Payload(\"storage\")] public class StoragePayload : Payload { private uint [] items ; public uint [] Items { get { return this . items ; } set { this . items = value ; } } public StoragePayload ( uint [] items ) { this . items = items ; } public override void ReadWriteCore ( BitcoinStream stream ) { stream . ReadWrite ( ref this . items ); } public override string ToString () { return base . ToString () + \" : \" + this . Items ; } } } Then you also need a behavior that will process messages. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 using System ; using System.Collections.Generic ; using System.Linq ; using System.Threading.Tasks ; using Blockcore.Connection ; using Blockcore.Interfaces ; using Blockcore.P2P.Peer ; using Blockcore.P2P.Protocol ; using Blockcore.P2P.Protocol.Behaviors ; using Blockcore.P2P.Protocol.Payloads ; using Blockcore.Signals ; using Blockcore.Utilities ; using Microsoft.Extensions.Logging ; using NBitcoin ; namespace Blockcore.Features.Storage { /// <summary> /// Peer behavior for memory pool. /// Provides message handling of notifications from attached peer. /// </summary> public class StorageBehavior : NetworkPeerBehavior { /// <summary>Connection manager for managing peer connections.</summary> private readonly IConnectionManager connectionManager ; /// <summary>Provider of IBD state.</summary> private readonly IInitialBlockDownloadState initialBlockDownloadState ; /// <summary>Instance logger for the memory pool behavior component.</summary> private readonly ILogger logger ; /// <summary>Factory used to create the logger for this component.</summary> private readonly ILoggerFactory loggerFactory ; /// <summary>The network that this component is running on.</summary> private readonly Network network ; /// <summary> /// Locking object for memory pool behaviour. /// </summary> private readonly object lockObject ; /// <summary> /// The min fee the peer asks to relay transactions. /// </summary> public Money MinFeeFilter { get ; set ; } public StorageBehavior ( IConnectionManager connectionManager , IInitialBlockDownloadState initialBlockDownloadState , ILoggerFactory loggerFactory , Network network ) { this . connectionManager = connectionManager ; this . initialBlockDownloadState = initialBlockDownloadState ; this . logger = loggerFactory . CreateLogger ( this . GetType (). FullName ); this . loggerFactory = loggerFactory ; this . network = network ; this . lockObject = new object (); } /// <inheritdoc /> protected override void AttachCore () { this . AttachedPeer . MessageReceived . Register ( this . OnMessageReceivedAsync ); } /// <inheritdoc /> protected override void DetachCore () { this . AttachedPeer . MessageReceived . Unregister ( this . OnMessageReceivedAsync ); } /// <inheritdoc /> public override object Clone () { return new StorageBehavior ( this . connectionManager , this . initialBlockDownloadState , this . loggerFactory , this . network ); } private async Task OnMessageReceivedAsync ( INetworkPeer peer , IncomingMessage message ) { try { await this . ProcessMessageAsync ( peer , message ). ConfigureAwait ( false ); } catch ( OperationCanceledException ) { this . logger . LogTrace ( \"(-)[CANCELED_EXCEPTION]\" ); return ; } catch ( Exception ex ) { this . logger . LogError ( \"Exception occurred: {0}\" , ex . ToString ()); throw ; } } private async Task ProcessMessageAsync ( INetworkPeer peer , IncomingMessage message ) { try { switch ( message . Message . Payload ) { case StoragePayload storagePayload : await this . ProcessStorageInPayloadAsync ( peer , storagePayload ). ConfigureAwait ( false ); break ; } } catch ( OperationCanceledException ) { this . logger . LogTrace ( \"(-)[CANCELED_EXCEPTION]\" ); return ; } } private async Task ProcessStorageInPayloadAsync ( INetworkPeer peer , StoragePayload message ) { Guard . NotNull ( peer , nameof ( peer )); if ( peer != this . AttachedPeer ) { this . logger . LogDebug ( \"Attached peer '{0}' does not match the originating peer '{1}'.\" , this . AttachedPeer ?. RemoteSocketEndpoint , peer . RemoteSocketEndpoint ); this . logger . LogTrace ( \"(-)[PEER_MISMATCH]\" ); return ; } List < uint > list = new List < uint >(); list . Add ( 1 ); list . Add ( 2 ); list . Add ( 3 ); await this . SendStorageAsync ( peer , list ); } private async Task SendStorageAsync ( INetworkPeer peer , List < uint > storageList ) { var queue = new Queue < uint >( storageList ); while ( queue . Count > 0 ) { uint [] items = queue . TakeAndRemove ( 5 ). ToArray (); if ( peer . IsConnected ) { this . logger . LogDebug ( \"Sending items to peer '{0}'.\" , peer . RemoteSocketEndpoint ); await peer . SendMessageAsync ( new StoragePayload ( items )). ConfigureAwait ( false ); } } } public async Task SendTrickleAsync () { INetworkPeer peer = this . AttachedPeer ; if ( peer == null ) { this . logger . LogTrace ( \"(-)[NO_PEER]\" ); return ; } this . logger . LogDebug ( \"Sending storage inventory to peer '{0}'.\" , peer . RemoteSocketEndpoint ); try { // Sample data to send. List < uint > list = new List < uint >(); list . Add ( 1 ); list . Add ( 2 ); await this . SendStorageAsync ( peer , list ). ConfigureAwait ( false ); } catch ( OperationCanceledException ) { this . logger . LogTrace ( \"(-)[CANCELED_EXCEPTION]\" ); return ; } } } } Then finally you need your custom feature: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 using System.Collections.Generic ; using System.Linq ; using System.Threading.Tasks ; using Blockcore.AsyncWork ; using Blockcore.Builder ; using Blockcore.Builder.Feature ; using Blockcore.Configuration.Logging ; using Blockcore.Connection ; using Blockcore.Features.Storage.Persistence ; using Blockcore.P2P.Peer ; using Blockcore.P2P.Protocol.Payloads ; using Blockcore.Utilities ; using Microsoft.Extensions.DependencyInjection ; namespace Blockcore.Features.Storage { public class StorageFeature : FullNodeFeature { /// <summary>The async loop we need to wait upon before we can shut down this manager.</summary> private IAsyncLoop asyncLoop ; /// <summary>Factory for creating background async loop tasks.</summary> private readonly IAsyncProvider asyncProvider ; /// <summary> /// Connection manager injected dependency. /// </summary> private readonly IConnectionManager connection ; /// <summary>Global application life cycle control - triggers when application shuts down.</summary> private readonly INodeLifetime nodeLifetime ; private readonly PayloadProvider payloadProvider ; private readonly StorageBehavior storageBehavior ; public StorageFeature ( IConnectionManager connection , INodeLifetime nodeLifetime , IAsyncProvider asyncProvider , PayloadProvider payloadProvider , StorageBehavior storageBehavior ) { this . connection = connection ; this . nodeLifetime = nodeLifetime ; this . payloadProvider = payloadProvider ; this . asyncProvider = asyncProvider ; this . storageBehavior = storageBehavior ; } public override Task InitializeAsync () { // Register the behavior. this . connection . Parameters . TemplateBehaviors . Add ( this . storageBehavior ); // Register the payload types. this . payloadProvider . AddPayload ( typeof ( StoragePayload )); // Make a worker that will filter connected knows that has announced our custom payload behavior. this . asyncLoop = this . asyncProvider . CreateAndRunAsyncLoop ( \"Storage.SyncWorker\" , async token => { IReadOnlyNetworkPeerCollection peers = this . connection . ConnectedPeers ; if (! peers . Any ()) { return ; } // Announce the blocks on each nodes behavior which supports relaying. IEnumerable < StorageBehavior > behaviors = peers . Where ( x => x . PeerVersion ?. Relay ?? false ) . Select ( x => x . Behavior < StorageBehavior >()) . Where ( x => x != null ) . ToList (); foreach ( StorageBehavior behavior in behaviors ) { await behavior . SendTrickleAsync (). ConfigureAwait ( false ); } }, this . nodeLifetime . ApplicationStopping , repeatEvery : TimeSpans . FiveSeconds , startAfter : TimeSpans . TenSeconds ); return Task . CompletedTask ; } } /// <summary> /// A class providing extension methods for <see cref=\"IFullNodeBuilder\"/>. /// </summary> public static class FullNodeBuilderStorageExtension { public static IFullNodeBuilder UseStorage ( this IFullNodeBuilder fullNodeBuilder ) { LoggingConfiguration . RegisterFeatureNamespace < StorageFeature >( \"storage\" ); fullNodeBuilder . ConfigureFeature ( features => { features . AddFeature < StorageFeature >() . FeatureServices ( services => { services . AddSingleton < IDataStore , DataStore >(); services . AddSingleton < StorageBehavior >(); }); }); return fullNodeBuilder ; } } } This is basically all you need to start building custom data payload features ontop of your network of Blockcore nodes.", "title": "Your own custom payload"}]}